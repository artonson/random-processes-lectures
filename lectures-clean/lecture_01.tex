\section{Введение в курс}
Как понятно из названия, этот пункт посвящён простой цели: вспомнить основные 
понятия, необходимые для дальнейшего чтения. Начнём с самого основного: 
\emph{вероятностного} пространства.

\begin{definition}
	Вероятностное пространство, или \emph{тройка Колмогорова}~--- это тройка 
	\((\Omega, \F, \Pr)\), где
	\begin{itemize}
		\item \(\Omega\)~--- простанство элементарных исходов. 
		\item \(\F\)~--- \(\sigma\)-алгебра над \(\Omega\), пространство 
		событий. Неформально говоря, \(\F\) определяет объекты, относительно 
		которых делаются утверждения. 
		\item \(\Pr : \F \mapsto [0, 1]\)~--- вероятностная мера. 
	\end{itemize}
\end{definition}

На всякий случай напомню определения сигма-алгебры и вероятностной меры.
\begin{definition}
	\emph{\(\sigma\)-алгебра} над множеством \(A\)~--- это множество \(\F 
	\subseteq 
	2^{A}\), обладающее следующими свойствами:
	\begin{enumerate}
		\item \(\emptyset \in \F\).
		\item Если \(X \in \F\), то и дополнение \(A \setminus X \in \F\).
		\item \(\F\) замкнуто относительно счётного объединения, то есть 
		объединение счётного подсемейства из \(\F\) лежит в \(\F\).\footnote{То 
		есть это алгебра, к которой конечное объединение заменено на счётное.}
	\end{enumerate}
\end{definition}

\begin{definition}
	Пусть \(\Omega\)~--- пространство элементарных исходов, а \(\F\)~--- 
	\(\sigma\)-алгебра его подмножеств (пространство событий). 
	\emph{Вероятностной мерой} или же вероятностью называется функция \(\Pr : 
	\F \mapsto [0, 1]\), удовлетворяющая двум свойствам:
	\begin{enumerate}
		\item (счётная аддитивность) Пусть \(\{A_{n}\}_{n = 1}^{\infty}\)~--- 
		последовательность попарно не пересекающихся событий. Тогда
		\[
		\Pr{\bigsqcup_{n = 1}^{\infty} A_{n}} = \sum_{n = 1}^{\infty} 
		\Pr{A_{n}}
		\]
		
		\item (нормированность) \(\Pr{\Omega} = 1\).
	\end{enumerate}
\end{definition}

Теперь посмотрим на несколько примеров вероятностных пространств.
\begin{example}
    Допустим, что человек бросает монетку. В данном случае элементарными 
    исходами являются ``орёл'' и ``решка''.  Обозначим их за 0 и 1 
    соответственно. Тогда вероятностное пространство будет устроено следующим 
    образом: пространство элементарных исходов \(\Omega = \{0, 1\}\), 
    пространство событий \(\F = \{\emptyset, \{0\}, \{1\}, \Omega\}\), а 
    вероятность \(\Pr\) определяется следующим образом: 
    \[
        \Pr{\emptyset} = 0, \quad \Pr{\{1\}} = p, \quad \quad \Pr{\{0\}} = 1 - 
        p,\quad \quad \Pr{\Omega} = 1, \quad p \in [0, 1].
	\]
\end{example}

\begin{example}
    Теперь подбросим монетку \(n\) раз. В таком случае \(\Omega = \{0, 
    1\}^{n}\), то есть если \(\omega \in \Omega\), то \(\omega = (\omega_{1}, 
    \ldots, \omega_{n})\), где \(\omega_{i} \in \{0, 1\}\). Пространство 
    событий же введём просто как множество всех подмножеств: \(\F = 
    2^{\Omega}\). Введение же вероятностной меры оставим читателю.
\end{example}

В дискретном случае алгебра событий, как известно, очень проста: обычно это 
просто множество всех подмножеств. Теперь перейдём от дискретного случая к 
более общему. Пусть \(\Omega = \R\). Как тогда ввести алгебру событий? Ведь, 
как известно, в \(\R\) есть неизмеримые подмножества. Для этого вводят 
\emph{борелевскую \(\sigma\)-алгебру} \(\B(\R)\) и говорят, что \(\F =\B(\R)\). 
Напомню определение:

\begin{definition}
    Борелевская \(\sigma\)-алгебра над \(\R\) \(\B(\R)\)~--- это минимальная 
    (по включению) сигма-алгебра над \(\R\), содержащая все полуинтервалы вида 
    \((a, b]\).\footnote{Хоть она и минимальна, но всё равно она огромна~--- 
    найти неборелевское множество не так уж и просто. }
\end{definition}

Всё это вводилось ради того, с чем мы работаем на постоянной основе: ради 
\emph{случайных величин}. 
\begin{definition}
    Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство. Случайной 
    величиной будем называть отображение \(\xi : \Omega \mapsto \R\) такое, что 
    для любого \(x \in \R\) событие \(\{\xi \leq x\} = \{\omega \in \Omega : 
    \xi(\omega) \leq x\}\) лежит в \(\F\).\footnote{Это свойство принято 
    называть измеримостью. Такое требование нужно для того, чтобы были 
    осмысленны вопросы типа ``Чему равна вероятность того, что значение 
    случайной величины будет лежать в таком-то отрезке?''.}
\end{definition}

Характеризовать поведение случайной величины помогает \emph{функция 
распределения}:
\begin{definition}
    Пусть \(\xi\)~--- случайная величина на вероятностном пространстве 
    \((\Omega, \F, \Pr)\). Функцией распределения случайной величины \(\xi\) 
    называют функцию \(F_{\xi} : \R \mapsto [0, 1]\), определяемую следующим 
    образом: \(F_{\xi}(x) = \Pr{\xi \leq x}\).
\end{definition}

Дальше по плану сходимости. Как известно, их четыре типа, и они не равноценны. 
Чтобы не повторяться, сразу же введём обозначения. Пусть \((\Omega, \F, 
\Pr)\)~--- вероятностное пространство, а \(\{\xi_{n}\}_{n = 1}^{\infty}\) и 
\(\xi\)~--- случайные величины на нём.
\begin{definition}
    \(\xi_{n}\) сходится к \(\xi\) почти наверное, если 
    \[
    \Pr{\left\{\omega \in \Omega : \lim\limits_{n \to \infty} 
        \xi_{n}(\omega) = \xi(\omega)\right\}} = 1.
    \]
    
    Обозначение: \(\xi_{n} \asto \xi\) или же просто \(\xi_{n} \to \xi\) (если 
    не указан вид сходимости и он не ясен из контекста, то сходимость идёт 
    почти наверное).
\end{definition}
\begin{definition}
    \(\xi_{n}\) сходится к \(\xi\) по вероятности, если для любого \(\epsilon > 
    0\)
    \[
    \lim\limits_{n \to \infty} \Pr{\{\omega \in \Omega : |\xi_{n}(\omega) - 
        \xi(\omega)| > \epsilon\}} = 0.
    \]
    
    Обозначение: \(\xi_{n} \prto \xi\).
\end{definition}
\begin{definition}
    \(\xi_{n}\) сходится к \(\xi\) в среднем порядка \(p\), если
    \[
        \lim\limits_{n \to \infty} \E{|\xi_{n} - \xi|^{p}} = 0.
    \]
    
    Обозначение: \(\xi_{n} \xrightarrow{L^{p}} \xi\).
   
    На практике обычно берётся \(p = 2\). В таком случае говорят, что имеет 
    место \emph{сходимость в среднеквадратичном смысле}. У такой сходимости 
    есть аж три разных обозначения: \(\xi_{n} \xrightarrow{L^{2}} \xi\), 
    \(\xi_{n} \sqmeanto \xi\) или же вообще \(\xi = \operatorname{l.i.m.} 
    \xi_{n}\).
\end{definition}
\begin{definition}
    \(\xi_{n}\) сходятся к \(\xi\) по распределению,\footnote{Она так 
    называется по той причине, что в одномерном случае её условие расносильно 
    сходиости функций распределения почти наверное.} если для любой 
    ограниченной непрерывной функции \(f : \R \mapsto \R\)
    \[
        \lim\limits_{n \to \infty} \E{f(\xi_{n})} = \E{f(\xi)}.
    \]
    
    Обозначение: \(\xi_{n} \dto \xi\).
\end{definition}

Цепочка взаимосвязей сходимостей устроена следующим образом. На данном рисунке 
\(p > s \geq 
1\) и стрелка из \(A\) в \(B\) означает ``из \(A\) следует \(B\)'':
\begin{center}
    \begin{tikzpicture}
    \begin{scope}
    \node (A) at (0, 0.5) {\(L^{p}\)};
    \node (B) at (2, 0.5) {\(L^{s}\)};
    \node (C) at (2, -0.5) {п.н.};
    \node (D) at (4, 0) {\(\Pr\)};
    \node (E) at (6, 0) {\(\mathrm{d}\)};
    \end{scope}
    
    \begin{scope}[>={Stealth[black]}]
    \path [->] (A) edge node {} (B);
    \path [->] (B) edge node {} (D);
    \path [->] (C) edge node {} (D);
    \path [->] (D) edge node {} (E);
    \end{scope}
    \end{tikzpicture}
\end{center}

Поехали дальше. Для случайных величин вводились такие вещи, как матожидание и 
дисперсия. Напомню:
\begin{definition}
    \emph{Математическое ожидание} случайной величины \(\xi\) с функцией 
    распределения \(F_{\xi}\) и плотностью \(p_{\xi}\)~--- это интеграл 
    \[
        \E{\xi} \equiv \int\limits_{-\infty}^{+\infty} x\diff F_{\xi}(x) = 
        \int\limits_{-\infty}^{+\infty} xp_{\xi}(x)\diff x
    \]
\end{definition}

Рядом с матожиданием вводятся \emph{дисперсия}, \emph{ковариация} и 
\emph{корреляция}.
\begin{definition}
    Дисперсией случайной величины \(\xi\) называется \(\D{\xi} = \E{(\xi - 
    \E{\xi})^{2}} = \E{\xi^{2}} - (\E{\xi})^{2}\). Корень из дисперсии 
    \(\sigma\) называется \emph{среднеквадратиным отклонением}.
\end{definition}
\begin{definition}
    Коварциацией случайных величин \(\xi\) и \(\eta\) называется 
    \[
        \cov(\xi, \eta) = \E{(\xi - \E{\xi})(\eta - \E{\eta})} = \E{\xi\eta} - 
        \E{\xi}\E{\eta}.
    \]
\end{definition}
\begin{definition}
    Корреляцией случайных величин \(\xi\) и \(\eta\) называется 
    \[
        \rho(\xi, \eta) = \frac{\cov(\xi, \eta)}{\sqrt{\D{\xi}\D{\eta}}}.
    \]
\end{definition}

В многомерном случае ситуация немного изменяется. Матожидание случайного 
вектора определяется, как вектор из матожиданий компонент. Ковариация (да и 
дисперсия тоже) случайных векторов \(\bm{\xi} \in \R^{m}\) и \(\bm{\eta} \in 
\R^{n}\) равна
\[
	\cov(\bm{\xi}, \bm{\eta}) = \E{(\bm{\xi} - \E{\bm{\xi}})(\bm{\eta} - 
	\E{\bm{\eta}})^{\intercal}} = (\cov(\xi_{i}, \eta_{j}))_{m \times n}.
\]

При анализе некоторых вещей могут понадобиться условные матожидания. Введём их.
\begin{definition}
	Пусть \(\xi\)~--- случайная величина, а \(\bm{\eta}\)~--- случайный вектор 
	из \(\R^{n}\). Тогда условным математическим ожиданием \(\xi\) относительно 
	\(\bm{\eta}\) называется случайная величина \(\E{\xi \given \bm{\eta}}\), 
	удовлетворяющая двум условиям:
	\begin{enumerate}
		\item \(\E{\xi \given \bm{\eta}} = \phi(\bm{\eta})\), где \(\phi : 
		\R^{n} \mapsto \R\)~--- некоторая борелевская функция (свойство 
		измеримости).
		\item Для любого \(B \in \B(\R^{n})\) \(\E{\xi\I\{\bm{\eta} \in B\}} = 
		\E{\E{\xi \given \bm{\eta}}\I\{\bm{\eta} \in B\}}\) (интегральное 
		свойство).
	\end{enumerate}
\end{definition}

Но считать условное матожидание по определению весьма грустно. Поэтому введём 
две теоремы, которые упрощают жизнь. Они опираются на понятие \emph{условного 
распределения} и условной плотности.
\begin{definition}
	\emph{Условным распределением} случайной величины \(\xi\) при условии, что 
	\(\bm{\eta} = \mathbf{y}\) назовём функцию \(\Pr{\xi \in B \given \bm{\eta} 
	= \mathbf{y}} \equiv \E{\I\{\xi \in B\} \given \bm{\eta} = \mathbf{y}}\), 
	рассматриваемую, как функцию от \(B \in \B(\R^n)\) при фиксированном 
	\(\mathbf{y} \in \R^k\).
\end{definition}

\begin{definition}
	Если условное распределение имеет плотность \(p_{\xi \mid \bm{\eta}}(x \mid 
	\mathbf{y})\), то назовём его \emph{условной плотностью \(\xi\) 
	относительно \(\bm{\eta}\)}. То есть для любого \(B \in \B(\R)\)
	\[
	\Pr{\xi \in B \given \bm{\eta} = \mathbf{y}} = \int\limits_{B} p_{\xi \mid 
	\bm{\eta}}(x \mid \mathbf{y})\diff x.
	\]
\end{definition}
\begin{theorem}[о вычислении условного математического ожидания]
	Пусть \(\xi\)~--- случайная величина, а \(f(x)\)~--- некоторая борелевская 
	функция. Если \(\E{|f(\xi)|} < +\infty\) и существует плотность \(p_{\xi 
	\mid \bm{\eta}}(x \mid \mathbf{y})\), то
	\[
	\E{f(\xi) \given \bm{\eta} = \mathbf{y}} = \int\limits_{\R} f(x)p_{\xi \mid 
	\bm{\eta}}(x \mid \mathbf{y})\diff x.
	\]
\end{theorem}
\begin{theorem}
	Пусть \(\xi\) и \(\eta\) таковы, что есть совместная плотность \(p_{\xi, 
	\eta}(x, y)\). Тогда существует условная плотность \(p_{\xi \mid \eta}(x 
	\mid y)\) и она равна
	\[
	p_{\xi \mid \eta}(x \mid y) = \dfrac{p_{\xi, \eta}(x, 
	y)}{p_{\eta}(y)}\I\left\{p_{\eta}(y) > 0\right\}
	\]
\end{theorem}

Обобщение на многомерный случай ровно такое же, как и для обычных матожиданий.

\section{Основы теории случайных процессов}

Теперь можно приступать к делу. Для начала введём понятие случайной функции.
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство, а \(T\)~--- 
	произвольное неслучайное множество (множество индексов). Тогда любое 
	множество случайных величин \(X = \{X_{t} \mid t \in T\}\) называется 
	\emph{случайной функцией}.
\end{definition}
Случайные функции можно классифицировать по строению множества индексов.
\begin{itemize}
	\item Если \(T = \{1\}\) (или любое другое одноэлементное множество), то 
	\(X = X_{1} : \Omega \mapsto \R\)~--- случайная величина.
	\item Если \(T = \{1, 2, \ldots, N\}\), то \(X = (X_{1}, \ldots, 
	X_{N})\)~--- случайный вектор.
	\item Если \(T\) дискретно (то есть не более, чем счётно), то \(X\) 
	называют \emph{случайной последовательностью}. Например, возьмём \(T = \N\) 
	и \(\Omega = \{0, 1\}\). Тогда случайная последовательность \(X = (X_t)_{t 
	\in T}\) соотвествует броскам монетки.
	\item Если \(T \subseteq \R\), то параметр \(t \in T\) можно 
	характеризовать, как время. В этом случае \(X\) принято называть 
	\emph{случайным процессом}.
	\item Аналогично, если \(T \subseteq \R^{d}\), где \(d \geq 1\), то 
	параметр можно характеризовать, как точку в \(d\)-мерном пространстве. 
	Тогда \(X\) называют \emph{случайным полем}. Например, если \(T = \R^{3}\), 
	то \(X_{t}(\omega)\) может соответствовать давлению в точке \(t = (x, y, 
	z)\) в момент времени \(\omega\).
\end{itemize}

Впрочем, данная классификация не является строгой. Например, понятие 
``случайный процесс'' обычно считается безусловным синонимом термина 
``случайная функция''.

Случайные процессы ещё разбивают по мощности множества индексов. Если оно не 
более, чем счётно, то говорят, что случайный процесс \emph{дискретен во 
времени}. Если же \(T\) континуально, то у случайного процесса 
\emph{непрерывное время}.

Рассмотрим несколько примеров.
\begin{example}
	Пусть \(T = \N\), а \(\{X_{n}\}_{n = 1}^{\infty}\)~--- последовательность 
	независимых и одинаково распределённых случайных величин с нулевым 
	матожиданием.\footnote{Для удобства в дальнейшем будем иногда сокращать 
	``независимые и одинаково распределённые'' до iid (independent and 
	identically distributed).} Тогда \(X = (X_t)_{t \in T}\)~--- случайный 
	процесс с дискретным временем, называемый \emph{белым шумом}. 
\end{example}
\begin{example}\label{random-walk}
	Пусть \(Y = (Y_t)_{t \in T}\)~--- последовательность iid случайных величин. 
	Тогда построим новую последовательность случайных величин следующим 
	образом: \(X_{t} = Y_{1} + \ldots + Y_{t}\). Тогда \(X = (X_{t})_{t \in 
	T}\)~--- случайный процесс с дискретным временем, называемый 
	\emph{случайным блужданием}. 
\end{example}
\begin{example}
	Пусть \(\xi_{1}, \ldots, \xi_{d}\)~--- случайные величины. Тогда 
	``случайный полином''
	\[
	X = (X_{t})_{t \in \R}, \quad X_t = \sum_{n = 1}^{d} \xi_{n}t^{n}
	\]
	образует случайный процесс.
\end{example}
\begin{example}\label{counting-process}
	Пусть некоторое устройство (например, жёсткий диск) начинает работу в 
	момент времени 0 и ломается в момент времени \(T_{1}\). В этот же момент 
	его меняют на новое (временем замены пренебрегаем). Оно, в свою очередь, 
	ломается спустя время \(T_{2}\), после чего его снова заменяют и этот 
	процесс продолжается. Введём случайные величины \(S_{n} = T_{1} + \dots + 
	T_{n}\). Случайный процесс \(S = (S_{t})_{t \in \N}\) называется процессом 
	моментов восстановления. Сечения будут соответствовать моментам 
	``восстановления''. Далее, введём следующий случайный процесс:
	\[
	N = (N_{t})_{t \in \R}, \quad N_{t} = \sum_{n = 1}^{\infty} 
	\I\{S_{n} \leq t\} = \#\{n \in \N \mid S_{n} \leq t\}.
	\]
	Этот процесс принято называть \emph{процессом восстановления}.
\end{example}

В дальнейшем нам понадобятся понятия \emph{сечения} и \emph{траектории} 
случайной функции. Введём их.

\begin{definition}
	Пусть \(X = (X_{t})_{t \in T}\)~--- случайная функция. Тогда \(X_{t}\) при 
	фиксированном \(t\) называется \emph{сечением} случайной функции.
\end{definition}

\begin{definition}
	Пусть \(X = (X_{t})_{t \in T}\)~--- случайная функция и \(\omega \in 
	\Omega\)~--- фиксированный исход. \emph{Траекторией} случайной функции
	называется функция \(\phi_{\omega} : T \mapsto \R\) такая, что 
	\(\phi_{\omega}(t) = X_{t}(\omega)\). 
\end{definition}

Теперь вопрос: есть случайный процесс. Как описать вероятность того, что 
реализация удовлетворяет какому-то условию? Да и вообще, какие вопросы можно 
задавать относительно реализаций? 

Посмотрим на пару частных случаев случайного процесса \(X = (X_{t})_{t \in T}\)
\begin{enumerate}
	\item Пусть \(T = \{1\}\). Тогда случайный процесс превращается в случайную 
	величину \(\xi\). Но её значения описываются функцией распределения 
	\(F_{\xi}(x) = \Pr{\xi \leq x}\).
	\item Аналогично, пусть \(T = \{1, 2, \dots, n\}\). Тогда \(X = (X_{1}, 
	\dots, X_{n})\)~--- это случайный вектор, а его значения описываются 
	совместной функцией распределения 
	\[
	F_{X}(x_{1}, \dots, x_{n}) = \Pr{X_{1} \leq x_{1}, \dots, X_{n} \leq 
		x_{n}}
	\]
\end{enumerate}

В конечном случае всё хорошо и можно обойтись совместной функцией 
распределения. А как перейти в бесконечный случай? Сделать прямое обобщение 
вряд ли получится: учитывать бесконечное число условий сложно и не факт, что 
возможно. Поэтому будем смотреть на конечные поднаборы. Тем 
самым мы пришли к следующему определению.
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство, \(T\)~--- 
	множество индексов, а \(X = (X_{t})_{t \in T}\)~--- случайный процесс. 
	Тогда \emph{семейством конечномерных распределений} случайного процесса 
	\(X\) называется набор \(F\) его конечномерных функций распределения
	\[
	F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) = \Pr{X_{t_{1}} \leq 
		x_{1}, \ldots, X_{t_{n}} \leq x_{n}},
	\]
	то есть
	\[
	F = \{F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) \mid n \in \N, 
	t_{1}, \dots, t_{n} \in T\}.
	\]
\end{definition}

\begin{example}
	Пусть \(X = (X_{t})_{t \in \N}\)~--- случайный процесс, состоящий из iid 
	случайных величин из распределения \(\mathcal{N}(\mu, \sigma^{2})\). Тогда
	\[
	F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) = \prod_{k = 1}^{n} 
	F_{X_{t_{k}}}(x_{k}) = \prod_{k = 1}^{n} \int\limits_{-\infty}^{x_{k}} 
	\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{-\frac{(y - 
		\mu)^{2}}{2\sigma^{2}}\right\}\diff y.
	\]
\end{example}

Вообще говоря, конечномерное распределение \(F_{t_{1}, \dots, t_{n}}(x_{1}, 
\dots, x_{n})\)~--- это распределение случайного вектора \((X_{t_{1}}, \dots, 
X_{t_{n}})\).

Как мы видим, по любому случайному процессу можно построить семейство 
конечномерных функций распределения. Теперь вопрос: а можно ли по семейству 
построить случайный процесс? Оказывается, что можно.
\begin{theorem}[Колмогорова о существовании случайного процесса]
	Пусть \(F\)~--- заданное семейство конечномерных функций распределения над 
	множеством индексов \(T\), которое удовлетворяет свойству согласованности: 
	для \(k < n\)
	\[
	F_{t_{1}, \dots, t_{k}}(x_{1}, \dots, x_{k}) = F_{t_{1}, \dots, 
		t_{n}}(x_{1}, \dots, x_{k}, +\infty, \dots, +\infty).
	\]
	Тогда существует вероятностное пространство \((\Omega, \F, \Pr)\) и 
	случайный процесс \(X = (X_{t})_{t \in T}\) такой, что \(\Pr{X_{t_{1}} \leq 
	x_{1}, \ldots, X_{t_{n}} \leq x_{n}} = F_{t_{1}, \dots, t_{n}}(x_{1}, 
	\dots, x_{n})\).
\end{theorem}
\begin{leftbar}
	\begin{small}\noindent
		Вообще, доказательство этой теоремы не особо сложное, но оно требует 
		введения не самых простых вещей наподобие борелевских сигма-аглебр над 
		пространством функций. Поэтому я лишь напишу идею.
	\end{small}
\end{leftbar}

Теперь вспомним, что независимость бесконечного набора~--- это независимость в 
совокоуности любого конечного поднабора. Тогда из теоремы Колмогорова сразу же 
получаем следующее
\begin{consequence}
	Пусть для каждого \(t \in T \subseteq \R\) определена одномерная функция 
	распределения \(F_{t}(x)\). Тогда существует вероятностное пространство 
	\((\Omega, \F, \Pr)\) и случайный процесс \(X = (X_{t})_{t \in T}\) с 
	независимыми сечениями такой, что \(\Pr{X_{t} \leq x} = F_{t}(x)\).
\end{consequence}

Теперь рассмотрим пример применения этой теоремы. Пусть \(T = [0, 1]\), а 
\[
F_{t_{1}, \ldots, t_{n}}(x_{1}, \ldots, x_{n}) = \prod_{k = 1}^{n} 
\int\limits_{-\infty}^{x_{k}} g(y)\diff y,
\]
где \(g\)~--- симметричная относительно нуля плотность. Возьмём случайный 
процесс \(X = (X_{t})_{t \in T}\) из теоремы Колмогорова. Несложно понять, что 
в таком случае
\[
\Pr{X_{t} > \epsilon, X_{s} < - \epsilon} = 
\left(\int\limits_{\epsilon}^{\infty}g(y)\diff y\right)^{2}
\]

Теперь возьмём последовательность событий \(A_{n} = \{X_{t} > \epsilon, X_{t + 
1/n} < -\epsilon\}\). Если процесс является непрерывным (поточечно), то \(A_n 
\to \emptyset\) при \(n \to \infty\). Но тогда нарушается непрерывность 
вероятностной меры в нуле, то есть \(\Pr{A_{n}} \not\to 0\). Следовательно, 
непрерывность, независимость и одинаковая распределённость не совместимы.

Для описания случайных величин вводились такие вещи, как матожидание, дисперсия 
и так далее. Так вот: их можно ввести и для случайных процессов, хотя это уже 
будут не константы, а функции (неслучайные).
\begin{definition}
	Математическое ожидание случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(m : T \mapsto \R\), устроенная следующим образом: \(m(t) = 
	\E{X_{t}}\).
\end{definition}
\begin{definition}
	Дисперсия случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(D : T \mapsto \R\), устроенная следующим образом: \(D(t) = 
	\D{X_{t}} = \E{(X_{t} - \E{X_{t}})^{2}}\).
\end{definition}
\begin{definition}
	Среднеквадратичное отклонение случайного процесса \(X = (X_{t})_{t \in 
		T}\)~--- это функция \(\sigma : T \mapsto \R\), устроенная следующим 
	образом: \(\sigma(t) = \sqrt{\D{X_{t}}}\).
\end{definition}
\begin{definition}
	Ковариационная функция случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(R : T^{2} \mapsto \R\), устроенная следующим образом: 
	\[
	R(t_{1}, t_{2}) = \cov(X_{t_{1}}, X_{t_{2}}) = \E{(X_{t_{1}} - 
		\E{X_{t_{1}}})(X_{t_{2}} - \E{X_{t_{2}}})}
	\]
\end{definition}
Наряду с ковариационной функцией вводят корреляционную функцию
\[
r(t_{1}, t_{2}) = \frac{R(t_{1}, t_{2})}{\sigma(t_{1})\sigma(t_{2})}
\]

Про неё нужно сказать, что по неравенству Коши-Буняковского-Шварца \(|r(t_{1}, 
t_{2})| \leq 1\).

Осталось ввести ещё одну функцию \(K : T^{2} \mapsto \R\), определяемую 
следующим образом: \(K(t_{1}, t_{2}) = \E{X_{t_{1}}X_{t_{2}}}\).

Теперь выпишем несколько очевидных свойств:
\begin{itemize}
	\item \(D(t) = R(t, t) \geq 0\), так как дисперсия неотрицательна.
	\item \(K(t_{1}, t_{2}) = \E{(X_{t_{1}} - m(t_{1}) + m(t_{1}))(X_{t_{2}} - 
		m(t_{2}) + m(t_{2}))}  = R(t_{1}, t_{2}) + m(t_{1})m(t_{2})\) 
		(проверьте!).
	\item \(R(t_{1}, t_{2}) = R(t_{2}, t_{1})\).
	\item Для любого \(n \in \N\) и наборов \((z_{1}, \ldots, z_{n})\), 
	\((t_{1}, \dots, t_{n})\) матрица \((R(t_{i}, t_{j}))_{n \times n}\) 
	неотрицательно определена:
	\[
	\sum_{i, j = 1}^{n} R(t_{i}, t_{i})z_{i}z_{j} \geq 0
	\]
	
	Это следует из того, что \((X_{t_{1}}, \dots, X_{t_{n}})\)~--- случайный 
	вектор, а \((R(t_{i}, t_{j}))_{n \times n}\) есть его матрица ковариаций.
\end{itemize}

Допустим, что у нас есть какой-то случайный процесс. Что произойдёт с его 
параметрами при линейном преобразовании?

Пусть \(X = (X_{t})_{t \in T}\)~--- случайный процесс, а \(a, b : T \mapsto 
\R\)~--- ограниченные неслучайные функции. Построим новый случайный процесс \(Y 
= (Y_{t})_{t \in T}\) следующим образом: \(Y_t = a(t)X_{t} + b(t)\). Посмотрим 
на матожидание, дисперсию и ковариационную функцию данного процесса. Для того, 
чтобы различать их для разных процессов, будем указывать название процесса в 
качестве индекса: например, \(R_{Y}(t_{1}, t_{2})\).
\begin{gather*}
	m_{Y}(t) = \E{Y_{t}} = \E{a(t)X_{t} + b(t)} = a(t)m_{X}(t) + b(t) \\
	R_{Y}(t_{1}, t_{2}) = \cov(Y_{t_{1}}, Y_{t_{2}}) = \cov(a(t_{1})X_{t_{1}} + 
	b(t_{1}), a(t_{2})X_{t_{2}} + b(t_{2})) = a(t_{1})a(t_{2})R_{X}(t_{1}, 
	t_{2}) \\
	D_{Y}(t) = R_{Y}(t, t) = a^{2}(t)R_{X}(t, t) = a^{2}(t)D_{X}(t)
\end{gather*}

Теперь сделаем небольшое обобщение и возьмём линейную комбинацию \(n\) 
процессов. Пусть \(X_{i} = (X_{t}^{i})_{t \in T}\), \(i = 1, \dots, n\), а 
\(a_{1}, \dots, 
a_{n}\)~--- набор ограниченных функций из \(T\) в \(\R\). Далее, строим новый 
случайный процесс \(Y = (Y_{t})_{t \in T}\) по следующему правилу:
\[
Y_{t} = \sum_{i = 1}^{n} a_{i}(t)X_{t}^{i} + b(t)
\]

Для упрощения жизни введём \emph{взаимную корреляционную функцию} \(R_{X_{i}, 
X_{j}}(t_{1}, t_{2}) = \cov(X_{t_{1}}^{i}, X_{t_{2}}^{j})\). Тогда несложно 
показать, что
\begin{gather}
	m_{Y}(t) = \sum_{i = 1}^{n} a_{i}(t)m_{X_{i}}(t) + b(t) \\
	R_{Y}(t_{1}, t_{2}) = \sum_{i = 1}^{n} 
	a_{i}(t_{1})a_{i}(t_{2})R_{X_{i}}(t_{1}, t_{2}) + \sum_{\substack{i, j = 1 
			\\ i \neq j}}^{n}a_{i}(t_{1})a_{j}(t_{2})R_{X_{i}, X_{j}}(t_{1}, 
			t_{2}) \\
	D_{Y}(t) = \sum_{i = 1}^{n} a^{2}_{i}(t)D_{X_{i}}(t) + \sum_{\substack{i, j 
			= 1 \\ i \neq j}}^{n}a_{i}(t)a_{j}(t)R_{X_{i}, X_{j}}(t, t)
\end{gather}

\section{Непрерывность случайных процессов}
Вообще, случайные функции~--- тоже вполне себе функции, поэтому вполне 
осмысленно посмотреть на её непрерывность. Только в данном случае можно вводить 
разные виды непрерывности, так как последовательности сходятся не только 
поточечно.
\begin{definition}
	Случайный процесс \(X = (X_{t})_{t \in T}\) непрерывыен в 
	среднеквадратичном смысле в точке \(t \in T\), если
	\[
	X_{t + \epsilon} \sqmeanto X_{t} \text{ при } \epsilon \to 0.
	\]
	Если это выполнено для любого \(t \in T\), то процесс называют непрерывным 
	в среднеквадратичном смысле.
\end{definition}

Вот есть у нас процесс. Можем ли мы сказать, что он будет непрерывным в 
среднеквадратичном смысле, не вспоминая определение каждый раз? Можем.
\begin{theorem}
	Случайный процесс \(X = (X_{t})_{t \in T}\) непрерывен в среднеквадратичном 
	случае тогда и только тогда, когда непрерывны \(R(t_{1}, t_{2})\) и 
	\(m(t)\).
\end{theorem}
\begin{proof}
	Для начала проверим, что этого условия достаточно. Действительно, из 
	непрерывности \(R(t_{1}, t_{2})\) и \(m(t)\) следует непрерывность \(K(t, 
	t)\) и
	\[
	\E{(X_{t + \epsilon} - X_{t})^{2}} = \E{X_{t + \epsilon}^{2}} + 
	\E{X_{t}^{2}} - 2\E{X_{t}X_{t + \epsilon}} = K(t + \epsilon, t + 
	\epsilon) + K(t, t) - 2K(t, t + \epsilon).
	\]
	
	Устремляя \(\epsilon\) к нулю, получаем, что \(\E{(X_{t + \epsilon} - 
		X_{t})^{2}} \to 0\), что и даёт непрерывность в среднеквадратичном 
		смысле. 
	Теперь покажем, что это условие необходимо. Для этого воспользуемся 
	следующей леммой:
	\begin{lemma}
		Пусть \(\{X_{n}\}_{n = 1}^{\infty}\), \(\{Y_{n}\}_{n = 1}^{\infty}\), 
		\(X\) и \(Y\)~--- случайные величины такие, что \(X_{n} \sqmeanto X\), 
		\(Y_{n} \sqmeanto Y\), \(\E{X^{2}} < \infty\) и \(\E{Y^{2}} < \infty\). 
		Тогда 
		\[
		\lim\limits_{m, n \to \infty} \E{X_{n}Y_{m}} = \E{XY}.
		\]
	\end{lemma}
	
	\begin{leftbar}
	\begin{small}\noindent 
	\begin{proof}
		Для начала покажем, что \((\E{XY})^{2} \leq \E{X^{2}}\E{Y^{2}}\). Для 
		этого рассмотрим \(f(t) = \E{(tX + Y)^{2}}\). Понятно, что \(f(t)\) 
		есть квадратный трёхчлен от \(t\) и он неотрицателен. Тогда его 
		дискриминант отрицателен и мы получаем желаемое. По сути, это просто 
		неравенство Коши-Буняковского-Шварца.
				
		Заметим, что по нему
		\[
			|\E{(X_{n} - X)(Y_{m} - Y)}| \leq \sqrt{\E{(X_{n} - 
			X)^{2}}\E{(Y_{n} - Y)^{2}}} \to 0.
		\]
				
		Теперь раскроем скобки:
		\[
			\E{(X_{n} - X)(Y_{m} - Y)} = \E{X_{n}Y_{m}} - \E{X_{n}Y} - 
			\E{XY_{m}} + \E{XY}
		\]
		
		Покажем, что \(\E{X_{n}Y} \to \E{XY}\). Действительно,
		\[
			\E{(X_{n} - X)Y} \leq \sqrt{\E{Y^2}\E{(X_{n} - X)^{2}}} \to 0.
		\]
		
		Аналогично, \(\E{XY_{m}} \to \E{XY}\). Тем самым мы получаем желаемое.
	\end{proof}
	\end{small}
	\end{leftbar}
	
	Из неё сразу же следует, что при \(\epsilon_{1}, \epsilon_{2} \to 0\)
	\[
	\begin{cases}
	X_{t_{1} + \epsilon_{1}} \sqmeanto X_{t} \\
	X_{t_{2} + \epsilon_{2}} \sqmeanto X_{t}
	\end{cases}
	\implies
	\E{X_{t_{1} + \epsilon_{1}}X_{t_{2} + \epsilon_{2}}} \to 
	\E{X_{t_{1}}X_{t_{2}}} \implies 
	K(t_{1} + \epsilon_{1}, t_{2} + \epsilon_{2}) \to K(t_{1}, t_{2})
	\]
	
	Это означает непрерывность \(K(t_{1}, t_{2})\). Теперь вспомним, что
	\[
	\D{|X_{t_{1}} - X_{t_{2}}|} = \E{(X_{t_{1}} - X_{t_{2}})^{2}} - 
	\left(\E{|X_{t_{1}} - X_{t_{2}}|}\right)^{2} \geq 0
	\]
	
	Отсюда сразу же следует, что при \(t_{1} \to t_{2}\) \(\E{|X_{t_{1}} - 
	X_{t_{2}}|} \to 0\). Следовательно, \(\E{X_{t_{1}}} \to \E{X_{t_{2}}}\) и 
	\(m(t)\) непрерывна. Отсюда получаем, что и \(R(t_{1}, t_{2})\) тоже 
	непрерывна.
\end{proof}

Но не среднеквадратичным случаем единым! У него весьма жёсткие требования, так 
что введём ещё пару видов.
\begin{definition}
	Будем говорить, что \(X = (X_{t})_{t \in T}\)~--- случайный процесс с 
	непрерывными траекториями, если для любого \(\omega \in \Omega\) траектория 
	\(\phi_{\omega}\) непрерывна, как функция от \(t\).
\end{definition}
\begin{example}
	Пусть \(T = [0, 1]\), \(f : [0, 1] \mapsto \R\)~--- какая-то непрерывная 
	функция, а \(\xi\)~--- случайная величина. Тогда случайный процесс \(X = 
	(X_{t})_{t \in T}\), построенный по правилу \(X_{t} = f(t)\xi\), будет 
	иметь непрерывные траектории.
\end{example}
\begin{definition}
	Будем говорить, что процесс \(X = (X_{t})_{t \in T}\) стохастически 
	непрерывен, если выполняется сходимость по вероятности: для любого 
	\(t \in X_{s} \prto X_{t}\) при \(s \to t\).
\end{definition}
\begin{example}
	Пусть для любого натурального 
	\(n\) \(T_{n}\)~--- это iid случайные величины с распределением 
	\(\mathrm{Exp}(\lambda)\), то есть их плотность равна \(p(z) = \lambda 
	e^{-\lambda z}\I\{z \geq 0\}\). Дальше, \(S_{n} = T_{1} + \ldots + T_{n}\), 
	а для любого \(t \geq 0\)
	\[
		N_{t} = \sum_{n = 1}^{\infty} \I\{S_{n} \leq t\} = \#\{n \in \N : S_{n} 
		< t\}.
	\]
	
	По сути, это процесс восстановления для экспоненциального распределения. 
	Далее мы докажем, что для него выполнено следующее свойство: для всех \(0 
	\leq s < t < +\infty\) \(N_{t} - N_{s} \sim \mathrm{Pois}(\lambda(t - 
	s))\). Но из него сразу же получается стохастическая непрерывность:
	\[
		\Pr{|N_{t} - N_{s}| > \epsilon} \leq \Pr{|N_{t} - N_{s}| > 0} = \sum_{k 
		= 1}^{\infty} \frac{(\lambda(t - s))^{k}}{k!}e^{-\lambda(t - s)} = 1 - 
		e^{-\lambda(t - s)} \xrightarrow[s \to t]{} 0.
	\]
\end{example}

Вообще говоря, между непрерывностями случайных процессов и видами сходимостей 
есть прямая связь. Например, если процесс непрерывен в среднеквадратичном 
смысле, то он будет стохастически непрерывен.

Ранее мы показали, что непрерывность исключает независимость. Можем ли мы 
сказать, что стохастическая непрерывность тоже исключает независимость? Можем. 
Пусть \(X = (X_{t})_{t \in T}\)~--- случайный процесс такой, что для 
какой-то окрестности \(t_{0}\) \(X_{t}\) независимо с \(X_{t_{0}}\) и \(X_{t}\) 
имеет плотность \(g(x)\). Посмотрим на вероятность отклониться на \(\epsilon\):
\[
\Pr{|X_{t} - X_{t_{0}}| > \epsilon} = \iint\limits_{|x - y| > \epsilon} 
g(x)g(y)\diff x \diff y.
\]

Но этот интеграл не стремится к нулю при \(t_{0} \to t\). Тогда стохастической 
непрерывности нет. Впрочем, как и непрерывных траекторий.