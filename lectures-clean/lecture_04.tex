\section{Марковские процессы}
Постепенно будем переходить от дискретного случая к общему. Пусть \(X = 
(X_{t})_{t \in T}\)~--- какой-то случайный процесс с непрерывным временем \(T 
\subseteq \R\). Обычно полагается, что \(T = \R_{+}\) или же \(T = \R\).  Как 
обобщить марковское свойство? Для этого нужно ввести понятие фильтрации:
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство и \(T \subseteq 
	\R\). Семейство \(\sigma\)-алгебр \(\{\F_{t}\}_{t \in T}\) такое, что
	\[
		\F_{s} \subset \F_{t} \subset \F,\quad \forall\,t > s, t, s \in T,
	\]
	называется \emph{фильтрацией вероятностного пространства}.
\end{definition}
Данное определение можно прояснить следующей интерпретацией: \(\F_{t}\)~--- 
совокупность событий, наблюдаемых до момента \(t\) (включительно).

\begin{definition}
	Пусть дан случайный процесс \(X = (X_{t})_{t \in T}\) с непрерывным 
	временем, определённый на некотором вероятностном пространстве. Определим
	\[
		\F_{t}^{X} = \sigma\{X_{s} \mid s \leq t, s, t \in T\}.
	\]
	
	Тогда \(\mathbb{F}^{X} = \{\F_{t}^{X}\}_{t \in T}\) называется 
	\emph{естественной фильтрацией} случайного процесса \(X\).
\end{definition}

Теперь можно дать понятие марковского свойства.
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство с фильтрацией 
	\(\{\F_{t}\}_{t \in T}\) по какому-то множеству \(T \subseteq \R\). Далее, 
	пусть \((E, \mathcal{E})\)~--- измеримое пространство (множество состояний 
	и сигма-алгебра на нём). Будем говорить, что случайный процесс \(X = 
	(X_{t})_{t \in T}\), определённый на этом фильтрованном вероятностном 
	пространстве, удовлетворяет \emph{марковскому свойству}, если \(\forall A 
	\in \mathcal{E}\) и любых \(s, t \in T\) таких, что \(s < t\) 
	\[
		\Pr{X_{t} \in A \given \F_{s}} = \Pr{X_{t} \in A \given X_{s}}.
	\]
\end{definition}
Суть этого определения та же, что и в дискретном случае: вероятность не зависит 
от предыстории.
\begin{definition}
	Случайный процесс \(X = (X_{t})_{t \in T}\) называется \emph{марковским}, 
	если он удовлетворяет марковскому свойству с естественной фильтрацией 
	\(\mathbb{F}^{X}\).
\end{definition}

\subsection{Дискретное множество событий. Ступенчатые процессы}
Теперь посмотрим на случай, когда \(E\) не более, чем счётно. В таком случае 
случайный процесс называют \emph{марковской цепью с непрерывным аргументом}. 
Для краткости такой процесс ещё называют \emph{ступенчатым} (из-за вида 
траекторий).
\begin{example}
	Оказывается, что однородный пуассоновский процесс является марковской цепью 
	с непрерывным аргументом (почему?).
\end{example}

Состояния удобно обозначать целыми числами, поэтому обычно полагается, что \(E 
= \Z_{+}\) или \(E = \Z\). 

Далее, для них тоже вводятся матрицы переходных вероятностей 
\(\mathbf{P}(t_{1}, t_{2}) = \|p_{ij}(t_{1}, t_{2})\|\) по правилу:
\[
	p_{ij}(t_{1}, t_{2}) = \Pr{X_{t_{2}} = j \given X_{t_{1}} = i}
\]

Теперь зафиксируем \(0 < t_{1} < t < t_{2}\). Тогда распишем переходную 
вероятность, пользуясь марковским свойством.
\begin{align*}
	p_{ij}(t_{1}, t_{2}) &= \Pr{X_{t_{2}} = j \given X_{t_{1}} = i} = \sum_{k 
	\in E} \Pr{X_{t_{2}} = j \given X_{t} = k, X_{t_{1}} = i}\Pr{X_{t} = k 
	\given X_{t_{1}} = i} = \\
	&= \sum_{k \in E} \Pr{X_{t_{2}} = j \given X_{t} = k}\Pr{X_{t} = k \given 
	X_{t_{1}} = i} = \sum_{k 
	\in E} p_{ik}(t_{1}, t)p_{kj}(t, t_{2}).
\end{align*}

Отсюда получается так называемое \emph{уравнение Колмогорова-Чепмена}, аналог 
которого мы получали ранее:
\[
	\textbf{P}(t_{1}, t_{2}) = \textbf{P}(t_{1}, t)\textbf{P}(t, t_{2}), \quad 
	t_{2} > t > t_{1} > 0.
\]

Теперь приступим к конструктивному описанию ступенчатого процесса. При этом 
наша цель будет состоять в получении соотношений, описывающих изменение 
распределения вероятностей состояния процесса во времени.

Введём специальный процесс \(Z = (Z_{t})_{t \geq 0}\) по правилу \(Z_{t} = 
\I\{\xi < t\}\), где \(\xi\)~--- неотрицательная случайная величина с функцией 
распределения \(F_{\xi}\) и плотностью \(p_{\xi}\). Оказывается, что \(Z\) 
является ступенчатым процессом.

Действительно, для любого натурального \(n\) и индексов \(t_{1} < t_{2} < 
\ldots < t_{n}\) верны следующие импликации: \(X_{t_{k}} = 1 \implies X_{t_{k + 
1}} = 1\) и \(X_{t_{k + 1}} = 0 \implies X_{t_{k}} = 0\). Тогда
\[
	\Pr{Z_{t_{n}} = 1 \given Z_{t_{1}} = z_{1}, \ldots, Z_{t_{n - 1}} = z_{n - 
	1}} = 
	\begin{cases}
	\Pr{Z_{t_{n}} = 1 \given Z_{t_{n - 1}} = z_{n - 1}}, & z_{n - 1} = 0 \\
	1, & z_{n - 1} = 1
	\end{cases}
\]

Аналогично рассматривается случай с \(Z_{n} = 0\). Тем самым мы показали, что 
выполнено марковское свойство и \(Z\) действительно является ступенчатым.

Теперь предположим, что выполнено следующее равенство, где \(\lambda(t)\)~--- 
неотрицательная функция, называемая \emph{интенсивностью}:
\[
	\Pr{X_{t + h} = 1 \given X_{t} = 0} = \lambda(t)h + o(h).
\]

Что из него следует? Оказывается, что это равенство задаёт распределение 
\(\xi\):
\begin{align*}
	\Pr{X_{t + h} = 1 \given X_{t} = 0} &= \Pr{\xi < t + h \given \xi \geq t} = 
	\frac{\Pr{t \leq \xi < t + h}}{\Pr{\xi \geq t}} = \frac{F_{\xi}(t + h) - 
	F_{\xi}(t)}{1 - F_{\xi}(t)} = \\ 
	&= \frac{p_{\xi}(t)h + o(h)}{1 - F_{\xi}(t)} = \lambda(t)h + o(h) \implies 
	\lambda(t) = \frac{p_{\xi}(t)}{1 - F_{\xi}(t)}
\end{align*}

Из полученного равенства несложно вытащить \(F_{\xi}\):
\[
	\frac{(1 - F_{\xi}(t))'}{1 - F_{\xi}(t)} = -\lambda(t) \implies F_{\xi}(t) 
	= 1 - \exp\left\{-\int\limits_{0}^{t}\lambda(\tau)\diff \tau\right\}.
\]

Если же \(\lambda(t) = \lambda = const\), то \(\xi \sim 
\mathrm{Exp}(\lambda)\). А, как известно, экспоненциальное распределение 
обладает эффектом отсутствия памяти, то есть
\[
	\Pr{\xi > s + t \given \xi \geq s} = \Pr{\xi > t}.
\]

Воспользуемся процессом \(Z\) для описания марковской цепи \(X\) с непрерывным 
временем и конечным множеством состояний \(E\). Сопоставим каждому состоянию 
\(i \in E\) случайный процесс \(Z_{i}\) с конечной интенсивностью 
\(\lambda_{i}(t)\). Каждый из процессов \(Z_{i}\) управляет моментом перехода 
процесса \(X(t)\) из \(i\)-го состояния в какое-либо другое. Введем для каждого 
\(i\) также относительные переходные вероятности \(\|q_{ij}(t)\|\), где 
\(q_{ij}(t)\) есть вероятность перейти в состояние \(j\) в момент времени \(t\) 
при условии, что в этот момент произошёл скачок в процессе \(Z_{i}\) (он 
управляет переходами) и до этого процесс находился в состоянии \(i\). Понятно, 
что
\[
	\sum_{j \in E, j \neq i} q_{ij}(t) = 1.
\]

Теперь поймём, как устроена реализация такого процесса. Пусть \(i_{0}\)~--- это 
начальное состояние процесса \(X\). В момент времени \(t_{0} = 0\) запускается 
процесс \(Z_{i_{0}}\). В момент его скачка \(t_{1}\) в соответствии с 
вероятностями \(\{q_{i_{0}j}(t_{1})\}_{j \in E}\) происходит переход его в иное 
(например, \(k\)-ое) состояние. В этот же момент запускается процесс \(Z_{k}\) 
c интенсивностью перехода \(\lambda_{k}(t)\). Далее, в момент \(t_{2}\) его 
скачка разыгрывается с вероятностями \(\{q_{kj}(t_{2})\}_{j \in E}\) переход 
процесса \(X\) в следующее состояние и так далее.

Теперь предположим, что все \(\lambda_{k}(t)\) и \(q_{ij}(t)\) есть константы. 
В таком случае процесс \(X\) однороден. Пока что ограничимся такими процессами.

Что мы можем сказать про вероятности для однородного ступенчатого процесса? Для 
достаточно малых \(h\) мы можем заменить интеграл его линейным приближением. 
Тогда
\[
	p_{ij}(h) \equiv p_{ij}(t, t + h) = \Pr{X_{t + h} = j \given X_{t} = i} =
	\begin{cases}
	\lambda_{i}q_{ij}h + o_{ij}(h), & i \neq j \\
	1 - \lambda_{i}h + o_{ii}(h), & i = j
	\end{cases}
\]
где \(o_{ij}(h)/h \to 0\) при \(h \to 0\).

Далее, пусть \(p_{i}(t) = \Pr{X_{t} = i}\). Применим формулу полной вероятности 
и выразим \(p_{j}(t + h)\):
\[
	p_{j}(t + h) = \sum_{i \in E} p_{ij}(h)p_{i}(t) = p_{j}(t)(1 - 
	\lambda_{j}h) + h\left(\sum_{i \in E, i \neq j}p_{i}(t)\lambda_{i}q_{ij} 
	+ \sum_{i \in E}\frac{o_{ij}(h)}{h}p_{i}(t)\right).
\]

Преобразуем выражение:
\[
	\frac{p_{j}(t + h) - p_{j}(t)}{h} = -\lambda_{j}p_{j}(t) + \sum_{i \in E, i 
	\neq j}p_{i}(t)\lambda_{i}q_{ij} + \sum_{i \in E} \frac{o_{ij}(h)}{h} 
	p_{i}(t).
\]

Теперь устремим \(h\) к нулю (это можно сделать, так как предел выражения 
справа действительно существует):
\[
	\frac{\diff p_{j}(t)}{\diff t} = -\lambda_{j}p_{j}(t) + \sum_{i \in E, i 
	\neq j}p_{i}(t)\lambda_{i}q_{ij}.
\]

Можно ввести коэффциценты
\[
	a_{ij} = \begin{cases}
	-\lambda_{j}, & i = j \\
	\lambda_{i}q_{ij}, & i \neq j
	\end{cases}
	\implies 
	\frac{\diff p_{j}(t)}{\diff t} = \sum_{i \in E}a_{ij}p_{i}(t).
\]

Получилось уравнение, которое называют \emph{уравнением Колмогорова}. В 
принципе, эти рассуждения работают и для счётного \(E\), только нужно добавить 
равномерную по \(i\) сходимость \(o_{ij}(h)/h\) к нулю и ограниченность  
\(\lambda_{i}\).

Мы получили уравнения, описывающие эволюцию распределения вероятностей 
состояний ступенчатого процесса во времени. Теперь хотелось бы получить 
аналогичные уравнения для переходных вероятностей. В данном случае с одним 
состоянием \(i\) связывается не один процесс, а целое семейство процессов 
\(\{Z_{ij}\}_{j \neq i}\) с интенсивностями \(\{\lambda_{ij}(t)\}_{j \neq i}\).

Первый скачок в этой совокупности потоков, одновременно ``запускаемых'' каждый 
раз в момент перехода процесса \(X\) в какое-либо очередное \(i\)-ое состояние, 
определяет момент перехода его в новое состояние и номер этого состояния 
(равный значению второго индекса того случайного процесса \(Z_{ij}(t)\), в 
котором раньше произошел скачок). 

Опять же, несложно понять, что при малых \(h\) верны следующие формулы :
\[
	p_{ij}(t, t + h) = 
	\begin{cases}
	\lambda_{ij}(t)h + o_{ij}(h), & i \neq j \\
	1 - \sum_{k \in E, k \neq j}\lambda_{ik}(t)h + o_{ii}(h), & i = j
	\end{cases}
\]

Теперь введём три условия:
\begin{itemize}
	\item Пусть все \(\lambda_{ij}(t)\) есть константы \(\lambda_{ij}\).
	\item Далее, пусть \(o_{ij}(h)/h\) равномерно сходится к нулю одновременно 
	по \(i\) и по \(j\).
	\item Напоследок, затребуем сходимость ряда \(\sum \lambda_{ij}\).
\end{itemize}

Теперь снова воспользуемся формулой полной вероятности для моментов времени 
\(t_{0} < t < t + h\):
\begin{align*}
	p_{ij}(t_{0}, t + h) &= \sum_{k \in E} p_{ik}(t_{0}, t)p_{kj}(t, t + h) = \\
	&= p_{ij}(t_{0}, t)p_{jj}(t, t + h) + \sum_{k \in E, k \neq j} 
	p_{ik}(t_{0}, t)p_{kj}(t, t + h) = \\
	&= p_{ij}(t_{0}, t)\left(1 - \sum_{k \in E, k \neq j}\lambda_{jk}h\right) + 
	\sum_{k \in E, k \neq j}\lambda_{kj}hp_{ik}(t_{0}, t) + o(h) = \\
	&= p_{ii}(t_{0}, t) + h\sum_{k \in E} b_{kj}p_{ik}(t_{0}, t) + o(h),
\end{align*}
где
\[
	b_{kj} = \begin{cases}
	\lambda_{kj}, & k \neq i \\
	-\sum_{i \in E, i \neq j} \lambda_{ji}, & k = i
	\end{cases}
\]

После преобразований и устремления \(h\) к нулю, получаем, что
\[
	\frac{\partial p_{ij}(t_{0}, t)}{\partial t} = \sum_{k \in E} 
	p_{ik}(t_{0}, t)b_{kj}
\]

Это так называемое \emph{прямое уравнение Колмогорова}. Несложно показать, 
аналоничным образом рассматривая формулу полной вероятности для \(t_{0} < t_{0} 
+ h < t\), что верно и \emph{обратное уравнение Колмогорова}:
\[
	\frac{\partial p_{ij}(t_{0}, t)}{\partial t_{0}} = -\sum_{k \in E} b_{ik} 
	p_{kj}(t_{0}, t)
\]

\subsection{Общий случай}
Теперь будем смотреть на случай, когда континуально не только время, но и 
множество состояний. В таком случае обычно полагается, что \(E = \R\). Однако в 
данном случае рассматриваются не переходные вероятности, а совместные функции 
распределения или плотности (если они есть) для пары сечений \(X_{1} = 
X_{t_{1}}\) и \(X_{2} = X_{t_{2}}\):
\[
	F(x, t_{2} \mid y, t_{1}) \equiv \Pr{X_{t_{2}} \leq x \given X_{t_{1}} 
	= y}, \quad p(x, t_{2} \mid y, t_{1}) \equiv \frac{\partial F(x, t_{2} \mid 
	y, t_{1})}{\partial x}.
\]

Можно ли найти связь для функций распределения в разные моменты времени, 
аналогичную дискретному случаю? Можно. Для начала сделаем неформальное 
обоснование. Пусть \(t_{0} < t < t_{1}\). Тогда для любого разбиения множества 
состояний \(\{v_{n}\}_{n \in \Z}\) верно следующее:
\[
	\Pr{X_{t_{1}} \leq x \given X_{t_{0}} = y} = \sum_{n = -\infty}^{+\infty} 
	\Pr{X_{t_{1}} \leq x \given v_{n} \leq X_{t} < v_{n + 1}, X_{t_{1}} = 
	y}\Pr{v_{n} \leq X_{t} < v_{n + 1} \given X_{t_{0}} = y}
\]

Введём обозначение:
\[
	\Delta F(v_{i}, t \mid y, t_{0}) = F(v_{i + 1}, t \mid y, t_{0}) - F(v_{i}, 
	t \mid y, t_{0}) = \Pr{v_{n} \leq X_{t} < v_{n + 1} \given X_{t_{0}} = y}
\]

Тогда
\[
	\Pr{X_{t_{1}} \leq x \given X_{t_{0}} = y} = \sum_{n = -\infty}^{+\infty} 
	\Pr{X_{t_{1}} \leq x \given v_{n} \leq X_{t} < v_{n + 1}, X_{t_{1}} = 
	y}\Delta F(v_{n}, t \mid y, t_{0})
\]

Как мы сказали ранее, это верно для любого разбиения прямой. Далее, это будет 
верно и при предельном переходе при диаметре разбиения, стремящемся к нулю. В 
пределе получится интеграл Стильтьеса:
\[
	F(x, t_{1} \mid y, t_{0}) = \int\limits_{E} F(x, t_{0} \mid z, t, 
	y, t_{0})\diff F(z, t \mid y, t_{0}),
\]
где \(F(x, t_{0} \mid z, t, y, t_{0}) = \Pr{X_{t_{1}} \leq x \given X_{t} = z, 
X_{t_{0}} = y}\). Согласно марковскому свойству второе условие можно убрать:
\[
	F(x, t_{1} \mid y, t_{0}) = \int\limits_{E} F(x, t_{0} \mid z, t)\diff F(z, 
	t \mid y, t_{0})
\]
Если же есть плотность, то это выражение можно записать 
немного по-другому, продифференцировав по \(x\):
\[
	p(x, t_{1} \mid y, t_{0}) = \int\limits_{E} p(x, t_{0} \mid z, t)p(z, t 
	\mid y, t_{0})\diff z.
\]

Полученные уравнения называются \emph{обобщёнными уравнениями Маркова}.

Основной вопрос, возникающий при изучении непрерывного марковского случайного 
процесса, как и прежде, состоит в анализе эволюции распределений (функции или
плотности распределения) его состояний с течением времени. Эти эволюции 
описываются первым и вторым уравнениями Колмогорова. Мы докажем первое 
уравнение Колмогорова для скалярного марковского процесса при достаточно 
жестких ограничениях.
\begin{theorem}[первое уравнение Колмогорова]
	Пусть \(X = (X_{t})_{t \in T}\)~--- марковский процесс, удовлетворяющий 
	трём условиям:
	\begin{itemize}
		\item Условная плотность \(p(x, t_{1} \mid y, t_{0})\) существует,  
		непрерыввно дифференцируема по \(t_{0}\), трижды непрерывно 
		дифференцируема по \(x_{0}\) и имеет ограниченные производные.
		\item Процесс ``непрерывен в \(L^{3}\)'', то есть для любого \(x\)
		\[
			\lim\limits_{\Delta t \to 0} \frac{1}{\Delta t}\E{(X_{t + \Delta t} 
			- X_{t})^{3} \given X_{t} = x} = 0.
		\]
		\item Существуют конечные пределы:
		\begin{gather}
			a(x, t) \equiv \lim\limits_{\Delta t \to 0} \frac{1}{\Delta 
			t}\E{X_{t + \Delta t} - X_{t} \given X_{t} = x} < \infty, \\
			b(x, t) \equiv \lim\limits_{\Delta t \to 0} \frac{1}{\Delta 
			t}\E{(X_{t + \Delta t} - X_{t})^{2} \given X_{t} = x} < \infty.
		\end{gather}
	\end{itemize}

	Тогда для любых \(t_{0} < t\)
	\[
		\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial t_{0}} + a(x_{0}, 
		t_{0})\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial x_{0}} + 
		\frac{b(x_{0}, t_{0})}{2}\frac{\partial^{2} p(x, t \mid x_{0}, 
		t_{0})}{\partial x_{0}^{2}} = 0.
	\]
\end{theorem}
\begin{remark}
	Коэффициент \(a(x, t)\) описывает начальную скорость изменения условного 
	математического ожидания процесса, поэтому его называют \emph{коэффициентом 
	сноса}. Коэффициент \(b(x, t)\) равным образом указывает на существование 
	конечной начальной скорости изменения условной дисперсии процесса. Отсюда 
	появилось его название~--- \emph{коэффицент диффузии}. 
	
	Полученное дифференциальное уравнение в частных производных позволяет 
	находить функцию условной плотности распределения по ее частным производным 
	в начальный момент времени. В связи с этим это уравнение часто называют 
	\emph{обратным уравнением Колмогорова}.
\end{remark}
\begin{proof}
	Возьмём три момента времени \(t_{0} < t_{0} + \Delta t < t\) и рассмотрим 
	соответсвующие сечения. Для них обобщённое уравнение Маркова имеет вид
	\[
		p(x, t \mid x_{0}, t_{0}) = \int\limits_{E} p(x, t \mid 
		z, t_{0} + \Delta t)p(z, t_{0} + \Delta t \mid x_{0}, t_{0})\diff z.
	\]
	
	Разложим \(p(x, t \mid z, t_{0} + \Delta t)\) в ряд Тейлора по \(z\) в 
	окрестности \(x_{0}\) до второго порядка с остаточным членом в форме 
	Лагранжа (\(\tilde{x} \in [x_{0}, x]\)): 
	\begin{multline*}
		p(x, t \mid z, t_{0} + \Delta t) = p(x, t \mid x_{0}, t_{0} + 
		\Delta t) + \frac{\partial p(x, t \mid x_{0}, t_{0} + \Delta 
		t)}{\partial x_{0}}(z - x_{0}) + \\ + 
		\frac{1}{2}\frac{\partial^{2} p(x, t_{0} \mid x_{0}, t_{0} + \Delta 
		t)}{\partial x_{0}^{2}}(z - x_{0})^{2} + 
		\frac{1}{6}\frac{\partial^{3} p(x, t_{0} \mid \tilde{x}, t_{0} + \Delta 
		t)}{\partial \tilde{x}^{3}}(z - x_{0})^{3}, 
	\end{multline*}

	Осталось подставить это разложение в интеграл:
	\begin{align*}
		p(x, t \mid x_{0}, t_{0}) &= p(x, t \mid x_{0}, t_{0} + \Delta 
		t)\int\limits_{E} p(z, t_{0} + \Delta t \mid x_{0}, t_{0})\diff z + \\ 
		&+ \frac{\partial p(x, t \mid x_{0}, t_{0} + \Delta t)}{\partial 
		x_{0}}\int\limits_{E} (z - x_{0})p(z, t_{0} + \Delta t \mid x_{0}, 
		t_{0})\diff z + \\
		&+ \frac{1}{2}\frac{\partial^{2} p(x, t_{0} \mid x_{0}, 
		t_{0} + \Delta t)}{\partial x_{0}^{2}}\int\limits_{E} (z - 
		x_{0})^{2}p(z, t_{0} + \Delta t \mid x_{0}, t_{0})\diff z + \\
		&+ \frac{1}{6}\frac{\partial^{3} p(x, t_{0} \mid \tilde{x}, t_{0} + 
		\Delta t)}{\partial \tilde{x}^{3}}\int\limits_{E} (z - 
		x_{0})^{3}p(z, t_{0} + \Delta t \mid x_{0}, t_{0})\diff z
	\end{align*}

	Немного преобразуем выражение и поделим на \(\Delta t\):
	\begin{multline*}
		-\frac{p(x, t \mid x_{0}, t_{0} + \Delta t) - p(x, t \mid x_{0}, 
		t_{0})}{\Delta t} = \\ 
		= \frac{\partial p(x, t \mid x_{0}, t_{0} + \Delta t)}{\partial x_{0}} 
		\left[\frac{1}{\Delta t}\int\limits_{E} (z - x_{0})p(z, t_{0} + \Delta 
		t \mid x_{0}, t_{0})\diff z\right] + \\
		+ \frac{1}{2}\frac{\partial^{2} p(x, t_{0} \mid x_{0}, t_{0} + \Delta 
		t)}{\partial x_{0}^{2}}\left[\frac{1}{\Delta t}\int\limits_{E} (z - 
		x_{0})^{2}p(z, t_{0} + \Delta t \mid x_{0}, t_{0})\diff z\right] + \\
		+ \frac{1}{6}\frac{\partial^{3} p(x, t_{0} \mid \tilde{x}, t_{0} + 
		\Delta t)}{\partial \tilde{x}^{3}}\left[\frac{1}{\Delta 
		t}\int\limits_{E} (z - x_{0})^{3}p(z, t_{0} + \Delta t \mid x_{0}, 
		t_{0})\diff z\right].
	\end{multline*}

	Теперь устремим \(\Delta t\) к нулю. Тогда, пользуясь условиями теоремы, 
	получаем, что
	\[
		-\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial t_{0}} = a(x_{0}, 
		t_{0})\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial x_{0}} + 
		\frac{b(x_{0}, t_{0})}{2}\frac{\partial^{2} p(x, t \mid x_{0}, 
		t_{0})}{\partial x_{0}^{2}}. \qedhere
	\]
\end{proof}

В целях упрощения вывода первого уравнения Колмогорова и получения её в форме, 
удобной для практики, мы исходили из существования условной плотности 
распределения процесса. Можно, однако получить это уравнение и в терминах 
условных функций распределения, что повышает её общность. Заметим также, что 
при несколько иных предположениях условие непрерывности процесса при выводе
уравнения может быть ослаблено, имея вид:
\[
	\lim\limits_{\Delta t \to 0} \frac{1}{\Delta t}\Pr{|X_{t + \Delta t} - 
	X_{t}| > \delta \given X_{t} = x} = 0.
\]

При определенным образом измененных условиях справедливо второе уравнение 
Колмогорова (называемое также уравнением Колмогорова-Фоккера-Планка), которое 
приводим без доказательства:
\begin{theorem}[второе уравнение Колмогорова]
	\[
		\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial t} = -a(x, 
		t)\frac{\partial p(x, t \mid x_{0}, t_{0})}{\partial x} + 
		\frac{b(x, t)}{2}\frac{\partial^{2} p(x, t \mid x_{0}, 
			t_{0})}{\partial x^{2}}.
	\]
\end{theorem}

Заметим, что случайные процессы рассмотренного типа носят название 
\emph{диффузионных}, поскольку они описывают, в частности, диффузию частиц.

\subsection{Модель системы массового обслуживания с непрерывным временем}

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
		% Setup the style for the states
		\tikzset{node style/.style={state, 
				fill=gray!20!white,
				rectangle}}
		
		\node[node style]                (I)   {Вход};
		\node[node style, right=of I]   (II)  {Очередь};
		\node[node style, above right=of II,minimum size=1.2cm]  (III) 
		{\(\text{УО}_{1}\) };
		\node[node style, below right=of II,minimum size=1.2cm]  (IV) 
		{\(\text{УО}_{m}\)};
		
		% Draw empty nodes so we can connect them with arrows
		\node[draw=none, left=of I]   (a)    {};
		\node[draw=none, below=of I]   (qI)   {};
		\node[draw=none, below=of II]  (qII)  {};
		\node[draw=none, right=of III] (qIII) {};
		\node[draw=none, right=of IV] (qIV) {};
		
		
		\draw[>=latex,auto=left,every loop]
		(a)   edge node {}			(I)
		(I)   edge node {\(Z_{3}\)}	(qI)
		(II)  edge node {\(Z_{4}\)} (qII)
		(II)  edge node {}			(III)
		(II)  edge node {}			(IV)
		(III) edge node {}			(qIII)
		(IV)  edge node {}			(qIV)
		(I)   edge node {\(Z_{1}\)}	(II);
		
		\draw[dashed,-] (III) edge node {} (IV);
		\draw[decorate,decoration={brace,amplitude=10pt}] (qIII) -- (qIV) node 
		[black,midway,xshift=0.7cm] {\(Z_{2}\)};
		
		\end{tikzpicture}
	\end{center}
	\caption{Графическое изображение модели системы массового обслуживания c 
	\(m\) устройствами обработки. \(Z_{1}\)~--- поток объектов, принятых на 
	обработку, \(Z_{2}\)~--- поток обработанных объектов, \(Z_{3}\)~--- поток 
	объектов, отклонённых от обработки из-за переполненности очереди, 
	\(Z_{4}\)~--- поток объектов, не дождавшихся обработки.}
\end{figure}

Ранее мы изучали модель системы массового обслуживания в дискретном времени. 
Теперь обобщим это понятие на непрерывное время, но с некоторыми изменениями. 
Теперь предположим, что у системы не один поток обработки, а \(m < \infty\). 
Далее, добавим новое свойство: пусть объект, ожидающий обслуживания в очереди 
(размер которой \(n < \infty\)), может в случайный момент времени покинуть её 
без обслуживания, если время пребывания его в очереди окажется больше значения 
случайной величины – времени ожидания \(T_{\text{ож}}\). Такая 
``нетерпеливость'' объектов определяется общим для них распределением этой 
случайной величины; каждому объекту приписывается её реализация.

Будем считать, что прибытие объектов, требующих обработки, покидание очереди 
без обработки, поступление на обработку, сама обработка и окончание из 
обслуживания независимы и могут происходить в любой момент времени.

Далее, состояние системы в момент времени \(t\), как и в дискретном случае, 
описывается числом находящихся в системе объектов. Понятно, что у системы будет 
\(n + m + 1\) состояние. По аналогии с дискретным случаем, введём события:
\[
	A_{k}(t) = \{\text{на момент времени } t \text{ в системе ровно } k \text{ 
	объектов}\}.
\]

Количество объектов сразу задаёт то, где находятся объекты. Если \(k \leq m\), 
то очередь пуста и заняты \(k\) линий обработки из \(m\). Если же \(m < k \leq 
m + n\), то все линии обработки заняты и в очереди \(k - m\) объектов. 

Далее, сделаем пару предположений о распределении параметров системы.
\begin{itemize}
	\item Пусть входной поток описывается однородным пуассоновским процессом с 
	интенсивностью \(\lambda\).
	\item Далее, пусть в каждом из устройств обработки время обработки 
	\(T_{\text{обр}}\) имеет одно и то же экспоненциальное распределение с 
	параметром \(\mu = 1/\E{T_{\text{обр}}}\). 
	\item Аналогично, время ожидания обработки для каждого объекта 
	\(T_{\text{ож}}\) имеет экспоненциальное распределение с параметром \(\nu = 
	1/\E{T_{\text{ож}}}\). 
\end{itemize}

Параметры \(\mu\) и \(\nu\) можно называть интенсивностями обслуживания 
объектов и покидания очереди соответственно. Это три предположения и свойства 
пуассоновского и экспоненциального распределений позволяют нам сказать, что 
полученная модель является марковским процессом.

Пусть \(t\) и \(t + \Delta t\)~--- два близких момента времени. Введём три 
обозначения:
\begin{itemize}
	\item Событие \(B_{k}\) будет обозначать ``за промежуток времени \((t, t + 
	\Delta t]\) в систему прибыло \(k\) новых объектов''. 
	
	Вероятность такого события описать несложно. По сути, она равна вероятности 
	\(\Pr{N_{t + \Delta t} - N_{t} = k}\):
	\[
		\Pr{B_{k}} = \frac{(\lambda\Delta t)^{k}}{k!}e^{-\lambda\Delta t} 
		\implies \begin{cases}
		\Pr{B_{0}} = 1 - \lambda\Delta t + o(\Delta t) \\
		\Pr{B_{1}} = \lambda\Delta t + o(\Delta t) \\
		\Pr{B_{k}} = o(\Delta t), & k > 1
		\end{cases}
	\]
	
	\item Событие \(D_{k}^{(l)}\) будет обозначать следующее: к моменту \(t + 
	\Delta t\) закончилась обработка \(l\) из \(k\) объектов, находящихся в 
	момент \(t\) в устройствах обработки и (или) поступивших в них за указанный 
	интервал.
	
	Как посчитать вероятность такого события? Воспользуемся независимостью и 
	тем, что объект будет обрабатываться всё время с вероятностью 
	\(e^{-\mu\Delta t}\):
	\[
		\Pr{D_{k}^{(l)}} = \binom{k}{l}(1 - e^{-\mu\Delta t})^{l}(e^{-\mu\Delta 
		t})^{k - l} \implies \begin{cases}
		\Pr{D_{k}^{(0)}} = 1 - k\mu\Delta t + o(\Delta t) \\
		\Pr{D_{k}^{(1)}} = k\mu\Delta t + o(\Delta t) \\
		\Pr{D_{k}^{(l)}} = o(\Delta t), & l > 1
		\end{cases}
	\]
	\item Событие \(F_{k}^{(l)}\) будет обозначать ``за этот отрезок очередь 
	покинуло \(l\) из \(k\) объектов, которые были в очереди до этого''. 
	Аналогично предыдущему пункту, вероятность считается так:
	\[
	\Pr{F_{k}^{(l)}} = \binom{k}{l}(1 - e^{-\nu\Delta t})^{l}(e^{-\nu\Delta 
		t})^{k - l} \implies \begin{cases}
	\Pr{F_{k}^{(0)}} = 1 - k\nu\Delta t + o(\Delta t) \\
	\Pr{F_{k}^{(1)}} = k\nu\Delta t + o(\Delta t) \\
	\Pr{F_{k}^{(l)}} = o(\Delta t), & l > 1
	\end{cases}
	\]
\end{itemize}

Если ``загнать'' события, вероятность которых есть \(o(\Delta t)\), в события 
вида \(O_{k}\), то можно записать следующие логические тождества:
\begin{gather}
	A_{0}(t + \Delta t) = (A_{0}(t) \cap B_{0}) \cup (A_{1} \cap B_{0} \cap 
	D_{1}^{(1)}) \cup O_{0} \\
	A_{1}(t + \Delta t) = (A_{0}(t) \cap B_{1} \cap D_{1}^{(0)}) \cup (A_{1}(t) 
	\cap B_{0} \cap D_{1}^{(0)}) \cup (A_{2}(t) \cap B_{0} \cap D_{2}^{(1)}) 
	\cup O_{1} \\
	\ldots
\end{gather}

Но при индексах \(m \leq k \leq m + n\) ситуация немного другая:
\begin{multline*}
	A_{m}(t + \Delta t) = (A_{m - 1}(t) \cap B_{1} \cap D_{m}^{(0)}) \cup 
	(A_{m}(t) \cap B_{0} \cap D_{m}^{(0)}) \cup \\ \cup (A_{m + 1}(t) \cap 
	B_{0} \cap F_{1}^{(0)} \cap D_{m}^{(1)}) \cup (A_{m + 1}(t) \cap 
	B_{0} \cap F_{1}^{(1)} \cap D_{m}^{(0)}) \cup O_{m}
\end{multline*}
\begin{multline*}
	A_{m + j}(t + \Delta t) = (A_{m + j - 1}(t) \cap B_{1} \cap D_{m}^{(0)} 
	\cap F_{j - 1}^{(0)}) \cup 
	(A_{m}(t) \cap B_{0} \cap D_{m}^{(0)} \cap F_{j}^{(0)}) \cup \\ \cup (A_{m 
	+ 1}(t) \cap B_{0} \cap ((F_{j + 1}^{(0)} \cap D_{m}^{(1)}) \cup (F_{j + 
	1}^{(1)} \cap D_{m}^{(0)}))) \cup O_{m + j}
\end{multline*}
\[
	A_{m + n}(t + \Delta t) = (A_{m + n - 1}(t) \cap B_{1} \cap D_{m}^{(0)}) 
	\cup (A_{m + n} \cap F_{n}^{(0)} \cap D_{m}^{(0)}) \cup O_{m + n} 
\]

Напоследок, добавим очевидное тождество: \(A_{0}(t) \cup \ldots \cup A_{n + 
m}(t) = \Omega\).

Осталось перейти к вероятностям, введя обозначение \(p_{i}(t) = \Pr{A_{i}(t)}\):
\begin{align*}
	p_{0}(t + \Delta t) &= p_{0}(t)(1 - \lambda\Delta t + o(\Delta t)) + 
	p_{1}(t)(1 - \lambda\Delta t + o(\Delta t))(\mu \Delta t + o(\Delta t)) + 
	o(\Delta t) = \\
	&= p_{0}(t) - \lambda \Delta t p_{0}(t) + \mu\Delta t p_{1}(t) + o(\Delta 
	t) \\
	p_{1}(t + \Delta t) &= p_{0}(t)(\lambda\Delta t + o(\Delta t))(1 - 
	\mu\Delta t + o(\Delta t)) + p_{1}(t)(1 - \lambda\Delta t + o(\Delta 
	t))\times \\ &\times (1 - \mu\Delta t + o(\Delta t)) + p_{2}(t)(1 - 
	\lambda\Delta t + o(\Delta t))(2\mu\Delta t + o(\Delta t)) + o(\Delta 
	t) = \\
	&= \lambda\Delta t p_{0}(t) + p_{1}(t) - (\lambda + \mu)\Delta t p_{1}(t) + 
	2\mu\Delta t p_{2}(t) + o(\Delta t) \\
	&\ldots \\
	p_{m}(t + \Delta t) &= p_{m - 1}(t)(\lambda\Delta t + o(\Delta 
	t))(1 - m\mu\Delta t + o(\Delta t)) + p_{m}(t)(1 - \lambda\Delta t + 
	o(\Delta t))\times \\ &\times (1 - m\mu\Delta t + o(\Delta t)) + p_{m + 
	1}(t)(1 - \lambda\Delta t + o(\Delta t))(m\mu\Delta t + o(\Delta t)) \times 
	\\ &\times (1 - \nu\Delta t + o(\Delta t)) + p_{m + 
	1}(t)(1 - \lambda\Delta t + o(\Delta t))(1 - m\mu\Delta t + o(\Delta t)) 
	\times \\ &\times (\nu\Delta t + o(\Delta t)) = p_{m - 1}(t)\lambda\Delta t 
	+ p_{m}(t) - (\lambda + \mu)\Delta t p_{m}(t) + \\ &+ (m\mu + \nu)\Delta t 
	p_{m + 1}(t) + o(\Delta t) \\
	p_{m + j}(t + \Delta t) &= p_{m + j - 1}(t)(\lambda\Delta t + o(\Delta 
	t))(1 - m\mu\Delta t + o(\Delta t))(1 - (j - 1)\mu\Delta t + o(\Delta t)) + 
	\\ &+ p_{m + j}(t)(1 - \lambda\Delta t + o(\Delta t))(1 - m\mu\Delta t + 
	o(\Delta t))(1 - j\mu\Delta t + o(\Delta t)) + \\ &+ p_{m + j + 1}(t)(1 - 
	\lambda\Delta t + o(\Delta t))(m\mu\Delta t + o(\Delta t))(1 - (j + 
	1)\mu\Delta t + o(\Delta t)) + \\ &+ p_{m + j + 1}(t)(1 - \lambda\Delta t + 
	o(\Delta t))(1 - m\mu\Delta t + o(\Delta t))((j + 1)\mu\Delta t + 
	o(\Delta t)) = \\ &= \lambda \Delta t p_{m + j - 1}(t) + p_{m}(t) - 
	(\lambda + m\mu + j\nu)\Delta t p_{m + j}(t) + \\ &+ (m\mu + (j + 
	1)\nu)\Delta t p_{m + j + 1}(t) + o(\Delta t) \\
	p_{m + n}(t + \Delta t) &= p_{m + n - 1}(t)(\lambda\Delta t + o(\Delta 
	t))(1 - m\mu\Delta t + o(\Delta t)) + p_{m + n}(t) \times \\ &\times (1 - 
	m\mu\Delta t + o(\Delta t))(1 - n\nu\Delta t + o(\Delta t)) = p_{m + n 
	- 1}(t)\lambda \Delta t + p_{m + n}(t) - \\ &- (m\mu + n\nu)p_{m + n}(t) + 
	o(\Delta t) \\
	1 &= p_{0}(t) + p_{1}(t) + \ldots + p_{n + m}(t)
\end{align*}

Попробуем найти стационарное решение. Для этого скажем, что \(p_{i}\) есть 
константы, после чего устремим к нулю:
\[
	\begin{cases}
	0 = -\lambda p_{0} + \mu p_{1} \\
	0 = \lambda p_{k - 1} - (\lambda + k\mu)p_{k} + (k + 1)\mu p_{k + 1}, & 1 
	\leq k < m \\
	0 = \lambda p_{m - 1} - (\lambda + \mu) p_{m} + (m\mu + \nu)p_{m + 1} \\
	0 = \lambda p_{m + j - 1} - (\lambda + m\mu + j\nu)p_{m + j} + (m\mu + (j + 
	1)\nu)p_{m + j + 1}, & 1 \leq j < n \\
	0 = \lambda p_{m + n - 1} - (m\mu + n\nu)p_{m + n} \\
	1 = p_{0} + p_{1} + \ldots + p_{m} + \ldots + p_{m + n}
	\end{cases}
\]

Опять же, в качестве упражнения оставим вывод решения этой системы:
\begin{gather*}
	\forall k \in \{1, 2, \ldots, m\}\ p_{k} = 
	\frac{(\lambda/\mu)^{k}}{k!}p_{0}, \\
	\forall j \in \{1, 2, \ldots, n\}\ p_{m + j} = 
	\frac{(\lambda/\mu)^{m}}{m!}\frac{\lambda^{j}}{\prod_{k = 1}^{j}(m\mu + 
	k\nu)}p_{0}, \\
	p_{0} = \left[\sum_{k = 0}^{m}\frac{(\lambda/\mu)^{k}}{k!} + 
	\frac{(\lambda/\mu)^{m}}{m!}\sum_{j = 1}^{n}\frac{\lambda^{j}}{\prod_{k = 
	1}^{j}(m\mu + k\nu)}\right]^{-1}
\end{gather*}

Осталось показать два частных случая:
\begin{itemize}
	\item Если устремить \(\nu\) к бесконечности, то получится \emph{система 
	без очереди}, в которой объекты, которые попали в очередь, моментально 
	выходят из неё. В этом случае \(p_{m + j} = 0\) для всех \(j \in \{1, 2, 
	\ldots, n\}\).
	\item Если же устремить \(\mu\) у нулю, то получится рассмотренная ранее 
	система массового обслуживания без покидания очереди.
\end{itemize}
