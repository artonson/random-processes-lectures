\section{Назад в прошлое: динамическое программирование}
Для описания некоторых алгоритмов, которые появятся дальше, будет нужен метод 
динамического программирования. Рассмотрим его на примере \emph{задачи объезда 
стран}:
\begin{problem}
	Путешественник хочет устроить турне: начиная с города \(x_{s}\) и 
	заканчивая городм \(x_{f}\), он хочет посетить \(k\) стран в определённой 
	последовательности. Далее, он ночует в каждой стране, которую посещает. 
	Однако у него мало денег, поэтому он хочет устроить турне с минимальными 
	затратами. Какие города он должен посетить?
\end{problem}
Понятно, что решать эту задачу перебором слишком долго: если в каждой стране 
\(n\) городов, то придётся рассмотреть \(n^{k}\) вариантов поездок. Попробуем 
немного улучшить эту оценку.

Пусть города задаются следующим образом: \(x_{ij}\) означает <<\(j\)-й город в 
\(i\)-й стране>> (для этого занумеруем все страны и все города в них). Далее, 
пусть \(f(x_{ij}, x_{i + 1, k})\)~--- стоимость проезда из города \(x_{ij}\) в 
город \(x_{i + 1, k}\), а \(h(x_{ij})\)~--- стоимость ночлега в городе 
\(x_{ij}\). Пользуясь этими обозначениями, введём \emph{функцию Беллмана} 
\(V(x)\) по следующему правилу: 
\[
	V(x_{s}) = 0, \quad V(x_{i + 1, k}) = \min\limits_{j}\left[V(x_{ij}) + 
	f(x_{ij}, x_{i + 1, k}) + h(x_{i + 1, k})\right].
\]

Оказывается, что смысл функции Беллмана \(V(x)\)~--- это наименьшая сумма, 
которую нужно затратить для того, чтобы добраться из города \(x_{s}\) в город 
\(x\). Это утверждение несложно доказать, пользуясь индукцией.

Пользуясь этой функцией, несложно получить решение. Введём функцию \(S(x)\), 
действующую по правилу
\[
	S(x_{i + 1, k}) = \arg\min\limits_{j}\left[V(x_{ij}) + f(x_{ij}, x_{i + 1, 
	k}) + h(x_{i + 1, k})\right].
\]

Тогда оптимальный путь \((x_{1}^{*}, \ldots, x_{k}^{*})\) может быть построен 
рекурсивным вызовом функции \(S\): \(x_{k}^{*} = S(x_{f})\), \(x_{m}^{*} = 
S(x_{m + 1}^{*})\). % надо бы доказать формально

Решение задачи объезда стран показывает пример применения метода динамического 
программирования. Но, понятное дело, этот метод далеко не универсален. Когда 
его применение оправдано?
\begin{itemize}
	\item Когда для решения задачи нужно решить перекрывающиеся подзадачи и их 
	решения можно запомнить.
	\item Когда задача обладает оптимальной подструктурой, или же кусочной 
	оптимальностью. Это означает следующее: например, если известно, что 
	оптимальный путь из \(A\) в \(B\) содержит \(C\) и \(D\) и известен 
	оптимальный путь из \(C\) в \(D\), то этот путь станет частью оптимального 
	пути из \(A\) в \(B\).
\end{itemize}

\section{Скрытые марковские модели}
\subsection{Мотивация и основные понятия}
Допустим, что мы хотим определить среднюю годовую температуру в каком-то месте 
на Земле за определённый период времени. Далее, усложним задачу тем, что 
возьмём очень давние времена~--- когда ещё не существовало термометров. К 
сожалению, отправиться назад в прошлое и замерить температуру не представляется 
возможным, поэтому придётся ориентироваться на косвенные признаки определённых 
температур.

Для простоты скажем, что температуру мы измеряем очень просто~--- различаются 
лишь состояния <<горячо>> и <<холодно>>. Предположим, что современные измерения 
показывают, что тёплый год следует за тёплым годом с вероятностью \(0,7\), а 
холодный за холодным~--- с вероятностью \(0,6\). Далее предположим (на не самом 
понятном основании, но не суть), что это предположение имеет место и для давних 
времён. Тогда переходная матрица будет устроена следующим образом (Г~--- 
горячо, Х~-- холодно):
\[
	\begin{blockarray}{ccc}
	& \text{Г} & \text{Х} \\
	\begin{block}{c(cc)}
	\text{Г} & 0,7 & 0,3 \\
	\text{Х} & 0,4 & 0,6 \\
	\end{block}
	\end{blockarray}
\]

Преположим, что исследование показало зависимость диаметра древесных колец от 
средней годовой температуры. Опять же, для простоты будем различать только три 
размера~--- маленькие (М), средние (С) и большие (Б). Напоследок предположим, 
что исследование показало следующую вероятностную зависимость между ними:
\[
\begin{blockarray}{cccc}
& \text{М} & \text{С} & \text{Б} \\
\begin{block}{c(ccc)}
\text{Г} & 0,1 & 0,4 & 0,5 \\
\text{Х} & 0,7 & 0,2 & 0,1 \\
\end{block}
\end{blockarray}
\]

Для данной системы \emph{состоянием} служит среднегодовая температура~--- либо 
<<горячо>>, либо <<холодно>>. При этом переход из текущего состояния в 
следующее является марковским (первого порядка%
\footnote{Марковская цепь называется цепью \(k\)-го порядка, если состояние 
зависит от \(k\) предыдущих состояний. По умолчанию будем считать, что все 
рассматриаемые нами модели имеют первый порядок.}%
), так как мы предположили, что он зависит только от текущего состояния и 
полностью задаётся переходной матрицей. Однако настоящее состояние 
<<спрятано>>, так как мы не можем его определить напрямую. 

Хоть мы и не можем наблюдать состояние (температуру) в прошлом, но мы можем 
замерить размер древесных колец. Вероятностная зависимость между диаметром 
колец и температурой даёт нам информацию о состоянии. Так как состояния 
<<скрыты>>, то такие системы называют \emph{скрытыми марковскими моделями}.

Теперь можно дать формальное определение.
\begin{definition}
	Скрытая марковская модель (первого порядка)~--- это вероятностная модель 
	последовательности, которая cостоит из набора \emph{наблюдаемых} переменных 
	\(\mathbf{X} = \{\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\}\), где 
	\(\mathbf{x}_{k} \in \R^{d}\), и набора \emph{латентных} (или 
	\emph{скрытых}) переменных 
	\[
		\mathbf{T} = \{\mathbf{t}_{1}, \ldots, \mathbf{t}_{n}\}, \quad 
		\mathbf{t}_{k} \in \{0, 1\}^{K}, \quad \sum_{i = 1}^{K} t_{ki} = 1.
	\] 
	
	В данной модели латентные переменные являются \emph{бинарными} и кодируют 
	\(K\) состояний, поэтому их иногда называют переменными состояния. Значения 
	наблюдаемого вектора \(\mathbf{x}_{k}\), взятого в момент времени \(k\), 
	зависит только от скрытого состояния \(\mathbf{t}_{k}\), которое, в свою 
	очередь, зависит только от скрытого состояния в предыдущий момент времени 
	\(\mathbf{t}_{k - 1}\).
\end{definition}

Скрытые марковские модели имеют множество применений: распознание речи, образов 
на видео, поведения, анализирование фондовых рынков, естественных языков, ДНК и 
так далее.

Теперь опишем то, как можно задать некоторые параметры вероятносной модели. 
Начнём с распределения \(\mathbf{t}_{n}\). Пусть в скрытой марковской модели 
\(K\) состояний. Закодируем их состояния в момент времени \(n\) бинарным 
вектором \(\mathbf{t}_{n} = (t_{n1}, \ldots, t_{nK})\) по правилу:
\[
	t_{ij} = 
	\begin{cases}
	1, & \text{система находится в состоянии } j \text{ в момент времени } i, \\
	0, & \text{иначе}.
	\end{cases}
\]

Так как в векторе \(\mathbf{t}_{n}\) может быть только один ненулевой элемент 
(предполагается, что система не может находиться в двух разных состояниях 
одновременно), то распределение \(\mathbf{t}_{n}\) относительно \(\mathbf{t}_{n 
- 1}\) \(p(\mathbf{t}_{n} \mid \mathbf{t}_{n - 1})\) можно задать матрицей 
\(\mathbf{A}\), где \(\mathbf{A}_{ij} = p(t_{nj} = 1 \mid t_{n - 1,i} = 1)\). 
Стоит заметить, что \(\sum_{j = 1}^{K} \mathbf{A}_{ij} = 1\). Следовательно, 
распределение можно записать следующим образом:
\[
	p(\mathbf{t}_{n} \mid \mathbf{t}_{n - 1}) = \prod_{i = 1}^{K}\prod_{j = 
	1}^{K} \mathbf{A}_{ij}^{t_{n - 1, i}t_{nj}}.
\]

Далее, нужно задать начальное распределение \(p(\mathbf{t}_{1})\). Пусть 
\(\pi_{i} = p(t_{1i} = 1)\). Тогда
\[
	p(\mathbf{t}_{1}) = \prod_{i = 1}^{K} \pi_{i}^{t_{1i}}.
\]

Хоть матрица \(\mathbf{A}\) может быть почти любой (нужна только 
неотрицательность элементов и равенство единице сумме элементов в строке), но с 
точки зрения скрытых марковских моделей более интересны матрицы \(\mathbf{A}\) 
с преобладающими элементами на диагонали (то есть более вероятно то, что 
система не изменит своего состояния). В этом случае можно сказать, что процесс 
находится в одном и том же состоянии в течение какого-то отрезка времени. 
Отсюда получаем простую физическую интерпретацию скрытой марковской модели: это 
процесс, который иногда меняет свои характеристики.

Теперь вспомним, что наблюдаемая переменная \(\mathbf{x}_{n}\) зависит только 
от переменной состояния \(\mathbf{t}_{n}\). Следовательно, разумно 
рассматривать условное распределение \(p(\mathbf{x}_{n} \mid \mathbf{t}_{n})\). 
Обычно предполагается, что оно известно с точностью до параметров \(\phi_{k}, k 
\in \{1, \ldots, K\}\): то есть, если \(t_{ni} = 1\), то \(p(\mathbf{x}_{n} 
\mid \mathbf{t}_{n}) = p(\mathbf{x}_{n} \mid \phi_{i})\). Следовательно,
\[
	p(\mathbf{x}_{n} \mid \mathbf{t}_{n}) = \prod_{k = 1}^{K} p(\mathbf{x}_{n} 
	\mid \phi_{k})^{t_{nk}}.
\]

Введённых выше параметров достаточно для полного описания скрытой марковской 
модели. Их собирают в \emph{набор параметров}
\[
	\Theta = (\bm{\pi}, \mathbf{A}, \bm{\phi}), \text{ где } \bm{\pi} = 
	(\pi_{1}, \ldots, \pi_{K}), \quad \bm{\phi} = (\phi_{1}, \ldots, \phi_{K}).
\]

Теперь можно сформулировать основные задачи теории скрытых марковских процессов:
\begin{itemize}
	\item \emph{Обучение с учителем}. Пусть есть некоторая последовательность 
	\(\mathbf{X}\), для которой известны латентные переменные \(\mathbf{T}\). 
	По обучающей выборке нужно оценить набор параметров \(\Theta\).
	\item \emph{Сегментация}. Пусть известна последовательность наблюдаемых 
	переменных \(\mathbf{X}\) и набор параметров \(\Theta\). По ним нужно 
	построить максимально правдоподобный набор латентных переменных 
	\(\mathbf{T}\), то есть найти \(\arg\max_{\mathbf{T}} p(\mathbf{T} \mid 
	\mathbf{X}, \Theta)\).
	\item \emph{Обучение без учителя}. Пусть известна последовательность 
	наблюдаемых переменных \(\mathbf{X}\) и число состояний \(K\). Нужно 
	оценить набор параметров \(\Theta\). Подзадача~--- \emph{нахождение 
	маргинального распределения}: найти \(p(t_{n} \mid \mathbf{X}, \Theta)\).
	\item \emph{Прогнозирование}. Пусть известна некоторая последовательность 
	\(\mathbf{X}\) длины \(N\). Нужно оценить наблюдаемый вектор в момент 
	времени \(N + 1\), то есть найти \(p(\mathbf{x}_{N + 1} \mid \mathbf{X})\).
\end{itemize}

\subsection{Пример 1: обучение с учителем}
Пусть дана обучающая выборка \((\mathbf{X}, \mathbf{T})\), представляющая 
собой одну или несколько последовательностей, в которых известны значения 
скрытых компонент. По ней нужно оценить набор параметров \(\Theta\). Как это 
сделать?

Для начала посмотрим на вероятность того, что обучающая выборка 
<<соответствует>> набору, то есть на \(p(\mathbf{X}, \mathbf{T} \mid \Theta)\). 
По построению скрытой марковской модели это распределение задаётся следующим 
образом:
\[
	p(\mathbf{X}, \mathbf{T} \mid \Theta) = 
	p_{\bm{\pi}}(\mathbf{t}_{1})\prod_{k = 1}^{N}p_{\bm{\phi}}(\mathbf{x}_{k} 
	\mid \mathbf{t}_{k})\prod_{k = 2}^{N}p_{\mathbf{A}}(\mathbf{t}_{k} \mid 
	\mathbf{t}_{k - 1}).
\]

Подставляем ранее выписанные формулы для \(p_{\bm{\pi}}(\mathbf{t}_{1})\), 
\(p_{\bm{\phi}}(\mathbf{x}_{k} \mid \mathbf{t}_{k})\) и 
\(p_{\mathbf{A}}(\mathbf{t}_{k} \mid \mathbf{t}_{k - 1})\):
\[
	p(\mathbf{X}, \mathbf{T} \mid \Theta) = \prod_{i = 1}^{K} 
	\pi_{i}^{t_{1i}}\left(\prod_{n = 1}^{N}\prod_{k = 1}^{K} p(\mathbf{x}_{n} 
	\mid \phi_{k})^{t_{nk}}\right)\left(\prod_{n = 2}^{K}\prod_{i = 
	1}^{K}\prod_{j = 1}^{K} \mathbf{A}_{ij}^{t_{n - 1, i}t_{nj}}\right)
\]

Оценивать \(\Theta\) будем с помощью метода максимального правдоподобия, то есть
\[
	\Theta_{ML} = \arg\max_{\Theta} p(\mathbf{X}, \mathbf{T} \mid \Theta) = 
	\arg\max_{\Theta} \log p(\mathbf{X}, \mathbf{T} \mid \Theta)
\]

Второе равенство корректно, так как \(\log{x}\)~--- монотонно возрастающая 
функция. Теперь выпишем \(\log p(\mathbf{X}, \mathbf{T} \mid \Theta)\):
\[
	\log p(\mathbf{X}, \mathbf{T} \mid \Theta) = \sum_{i = 1}^{K}t_{1i}\log 
	\pi_{i} + \sum_{n = 1}^{N}\sum_{k = 1}^{K} t_{nk}\log p(\mathbf{x}_{n} \mid 
	\phi_{k}) + \sum_{n = 2}^{N}\sum_{i = 1}^{K}\sum_{j = 1}^{K}t_{n - 1, 
	i}t_{nj}\log \mathbf{A}_{ij}.
\]

Для нахождения оценок воспользуемся методом Лагранжа. Вспомним, что на 
параметры наложены следующие ограничения:
\[
	\sum_{i = 1}^{K} \pi_{i} = 1, \quad \forall i \in \{1, 2, \ldots, K\}\ 
	\sum_{j = 1}^{K} A_{ij} = 1.
\]

Выпишем лагранжиан:
\[
	\mathcal{L}(\Theta, \lambda, \bm{\mu}) = \log p(\mathbf{X}, \mathbf{T} \mid 
	\Theta) + \lambda\left(\sum_{i = 1}^{K} \pi_{i} - 1\right) + \sum_{i = 
	1}^{K}\mu_{i}\left(\sum_{j = 1}^{K} A_{ij} - 1\right) \to \mathrm{extr}.
\]

Теперь начнём искать оценки.
\begin{itemize}
	\item Начнём с оценки \(\bm{\pi}\). Для неё
	\[
		\frac{\partial \mathcal{L}(\Theta, \lambda, \bm{\mu})}{\partial 
		\pi_{i}} = \frac{t_{1i}}{\pi_{i}} + \lambda = 0 \implies \pi_{i} = 
		-\frac{t_{1i}}{\lambda}.
	\]
	
	Теперь вспомним ограничения на \(\bm{\pi}\) и на \(\mathbf{t}_{1}\):
	\[
		\sum_{i = 1}^{K} \pi_{i} = -\frac{1}{\lambda}\sum_{i = 1}^{K} t_{1i} = 
		-\frac{1}{\lambda} = 1 \implies \pi_{i} = t_{1i}.
	\]
	
	\item Теперь оценим матрицу \(\mathbf{A}\):
	\[
		\frac{\partial \mathcal{L}(\Theta, \lambda, \bm{\mu})}{\partial 
		\mathbf{A}_{ij}} = \sum_{n = 2}^{N} \frac{t_{n - 1, i}t_{nj}}{A_{ij}} + 
		\mu_{i} = 0 \implies A_{ij} = \sum_{n = 2}^{N} \frac{t_{n - 1, 
		i}t_{nj}}{\mu_{i}}.
	\]
	
	Осталось избавиться от \(\mu_{i}\).
	\[
		\sum_{j = 1}^{K} A_{ij} = 1 \implies \sum_{j = 1}^{K}\sum_{n = 2}^{N} 
		\frac{t_{n - 1, i}t_{nj}}{\mu_{i}} = \sum_{n = 2}^{N} \frac{t_{n - 1, 
		i}}{\mu_{i}} = 1 \implies \mu_{i} = \sum_{n = 2}^{N} t_{n - 1, i}
	\]
	
	Отсюда получаем оценку:
	\[
		\mathbf{A}_{ij} = \frac{\sum_{n = 2}^{N} t_{n - 1, i}t_{nj}}{\sum_{n = 
		2}^{N} t_{n - 1, i}}.
	\]
	
	\item Осталось оценить \(\bm{\phi}\). Снова возьмём частную производную:
	\[
		\frac{\partial \mathcal{L}(\Theta, \lambda, \bm{\mu})}{\partial 
		\phi_{i}} = \sum_{n = 1}^{N}\sum_{k = 1}^{K} t_{nk} \frac{\partial \log 
		p(\mathbf{x}_{n} \mid \phi_{k})}{\partial \phi_{i}} = \sum_{n\,:\,
		t_{ni} = 1} \frac{\partial \log p(\mathbf{x}_{n} \mid 
		\phi_{i})}{\partial \phi_{i}} = 0.
	\]
	
	Получилась классическая задача на максимизацию правдоподобия по выборке iid 
	объектов. Получаем, что
	\[
		\phi_{i} = \arg\max\sum_{n\,:\,t_{ni} = 1} \log p(\mathbf{x}_{n} \mid 
		\phi_{i}).
	\]
	
	Для нахождения этого решения можно воспользоваться методами восстановления 
	плотностей. Об одном из них, EM-алгоритме, будет рассказано позднее.
\end{itemize}

\subsection{Пример 2: сегментация. Алгоритм Витерби}
Пусть нам известна последовательность наблюдаемых переменных \(\mathbf{X}\) и 
набор параметров скрытой марковской модели \(\Theta\). Как по ним построить 
максимально правдоподобный набор латентных переменных \(\mathbf{T}\)?

Как мы сказали ранее, нужный набор равен
\[
	\arg\max_{\mathbf{T}}p(\mathbf{T} \mid \mathbf{X}, \Theta).
\]

Теперь надо заметить, что \(p(\mathbf{X} \mid \Theta)\) не зависит от 
\(\mathbf{T}\). Тогда можно провести следующую цепочку равенств:
\[
	\arg\max_{\mathbf{T}}p(\mathbf{T} \mid \mathbf{X}, \Theta) = 
	\arg\max_{\mathbf{T}}\frac{p(\mathbf{X}, \mathbf{T} \mid 
	\Theta)}{p(\mathbf{X} \mid \Theta)} = \arg\max_{\mathbf{T}}p(\mathbf{X}, 
	\mathbf{T} \mid \Theta) = \arg\max_{\mathbf{T}}\log p(\mathbf{X}, 
	\mathbf{T} \mid \Theta).
\]

Оказывается, что это есть ни что иное, как задача динамического 
программирования! Действительно, вспомним задачу об объезде стран. Посмотрим на 
логарифм:
\[
	\log p(\mathbf{X}, \mathbf{T} \mid \Theta) = \sum_{i = 1}^{K}t_{1i}\log 
	\pi_{i} + \sum_{n = 2}^{N}\sum_{i = 1}^{K}\sum_{j = 1}^{K}t_{n - 1, 
	i}t_{nj}\log \mathbf{A}_{ij} + \sum_{n = 1}^{N}\sum_{k = 1}^{K} t_{nk}\log 
	p(\mathbf{x}_{n} \mid \phi_{k}).
\]

По аналогии с задачей, первое слагаемое определяет <<пункт отбытия>>, 
слагаемые второй суммы~--- стоимость переезда из одной страны в другую, а 
слагаемые третьей~--- <<стоимость ночлега>> в выбранном городе. Составим 
функцию Беллмана:
\[
	V(t_{1j}) = \log\pi_{j}, \quad V(t_{nj}) = \max_{i}\left[V(t_{n - 1, i}) + 
	t_{n - 1, i}t_{nj}\log \mathbf{A}_{ij} + t_{nj}\log p(\mathbf{x}_{n} \mid 
	\phi_{j})\right]
\]

Теперь, как и раньше, определяем функцию \(S\) по правилу
\[
	S(t_{1j}) = \emptyset, \quad S(t_{nj}) = \arg\max_{i}\left[V(t_{n - 1, i}) 
	+ t_{n - 1, i}t_{nj}\log \mathbf{A}_{ij} + t_{nj}\log p(\mathbf{x}_{n} \mid 
	\phi_{j})\right]
\]

Выполнив прямой обход по сигналу, мы определим значения \(V(t_{ij})\) и 
\(S(t_{ij})\). Далее, выполнив обратный проход, мы получим номера оптимальных 
состояний \((i^{*}(1), \ldots, i^{*}(N))\) по следующему правилу:
\[
	i^{*}(N) = \arg\max_{i}V(t_{Ni}), \quad i^{*}(k) = S(t_{k + 1,i^{*}(k + 1)})
\]

Легко понять, что \(\mathbf{t}_{k}\) определяются так: \(t_{k, i^{*}(k)} = 1\), 
\(t_{kl} = 0\) при \(l \neq i^{*}(k)\).

Чем так хорош этот алгоритм? Он позволяет достаточно быстро производить 
сегментацию очень длинных сигналов. Более того, при некоторых модификациях он 
может делать это в реальном времени (с небольшой задержкой, конечно).

\subsection{Пример 3: обучение без учителя. EM-алгоритм}
Преположим, что есть некоторая графическая модель, в которой известна лишь 
часть значений переменных, при этом атомарные распределения известны с 
точностью до набора параметров \(\Theta\). Нужно оценить \(\Theta\) по 
наблюдаемым величинам методом максимального правдоподобия, то есть найти
\[
	\Theta_{ML} = \arg\max_{\Theta} p(\mathbf{X} \mid \Theta).
\]

Это называют \emph{методом неполного правдоподобия}. По правилу суммирования 
неполное правдоподобие может быть получено суммированием по скрытым переменных 
полного правдоподобия, то есть
\[
	p(\mathbf{X} \mid \Theta) = \sum_{\mathbf{T}} p(\mathbf{X}, \mathbf{T} \mid 
	\Theta).
\]

Для многих моделей (в частности, для байесовских сетей) полное правдоподобие 
считается достаточно просто.

Далее, для удобства часто переходят к логарифму, что возможно из-за строгой 
монотонности \(\log x\). В частности, раньше мы получили явные формулы для 
\(\arg\max_{\Theta} p(\mathbf{X}, \mathbf{T} \mid \Theta) = \arg\max_{\Theta} 
\log p(\mathbf{X}, \mathbf{T} \mid \Theta)\). Вот здесь и возникает первый 
подводный камень. Из-за возникающего <<логарифма суммы>> оптимизация становится 
крайне сложной. 

Теперь построим итеративный алгоритм для нахождения \(\Theta_{ML}\), называемый 
\emph{EM-алго\-ритмом} (expectation-maximization algorithm). Смысл названия 
будет понятен немного позднее. Для начала введём обозначение для 
логарифмической функции правдоподобия: \(L(\Theta) = \log p(\mathbf{X} \mid 
\Theta)\).

Пусть после \(n\)-й итерации алгоритма мы получили значение \(\Theta_{n}\). Так 
как мы хотим максимизировать \(L(\Theta)\), то мы хотим получить значение 
\(\Theta\) такое, что разность
\[
	L(\Theta) - L(\Theta_{n}) = \log p(\mathbf{X} \mid \Theta) - \log 
	p(\mathbf{X} \mid \Theta_{n}).
\]
была максимальной. Заметьте, что мы пока что никак не трогали латентные или 
утерянные переменные. Если они есть, то EM-алгоритм предлагает естественный 
метод их включения. Периодически латентные переменные можно ввести просто как 
<<трюк>> для упрощения нахождения оценки максимального правдоподобия. В этом 
случае предполагается, что знание скрытых переменных успрощает анализ функции 
правдоподобия. 

Пусть \(\mathbf{T}\)~--- вектор скрытых переменных. Тогда по формуле полной 
вероятности
\[
	p(\mathbf{X} \mid \Theta) = \sum_{\mathbf{T}} p(\mathbf{X}, \mathbf{T} \mid 
	\Theta) = \sum_{\mathbf{T}} p(\mathbf{X} \mid \mathbf{T}, \Theta) 
	p(\mathbf{T} \mid \Theta).
\]

Тогда разность лог-функций правдоподобия можно записать в следующем виде:
\[
	L(\Theta) - L(\Theta_{n}) = \log\left(\sum_{\mathbf{T}} p(\mathbf{X} \mid 
	\mathbf{T}, \Theta) p(\mathbf{T} \mid \Theta)\right) - \log 
	p(\mathbf{X} \mid \Theta_{n})
\]
Мы вернулись к логарифму суммы. Для того, чтобы избавиться от него, 
воспользуемся \emph{неравенством Йенсена}, которое доказывалось в курсе 
математического анализа.
\begin{theorem}
	Пусть \(f\)~--- выпуклая (вниз) функция, определённая на интервале \((a, 
	b)\). Тогда для любых \(x_{1}, \ldots, x_{n} \in (a, b)\) и \(\lambda_{1}, 
	\ldots, \lambda_{n} > 0\) таких, что \(\lambda_{1} + \ldots + \lambda_{n} = 
	1\), выполнено следующее неравенство:
	\[
		f\left(\sum_{k = 1}^{n}\lambda_{k}x_{k}\right) \leq \sum_{k = 
		1}^{n}\lambda_{k}f(x_{k}).
	\]
	
	Если функция \(f\) выпукла вверх, то знак неравенства меняется на 
	противоположный.
\end{theorem}

Применим это неравенство следующим образом. Пусть \(\lambda_{i} = p(\mathbf{T} 
\mid \mathbf{X}, \Theta_{n})\). Несложно понять, что такие константы подходят. 
Далее, логарифм~--- выпуклая (вверх) функция, поэтому использование неравенства 
легально. Тогда <<подгоним>> выражение внутри логарифма под эти константы:
\begin{align*}
	L(\Theta) - L(\Theta_{n}) &= \log\left(\sum_{\mathbf{T}} p(\mathbf{X} \mid 
	\mathbf{T}, \Theta) p(\mathbf{T} \mid \Theta)\right) - \log 
	p(\mathbf{X} \mid \Theta_{n}) = \\
	&= \log\left(\sum_{\mathbf{T}} p(\mathbf{X} \mid 
	\mathbf{T}, \Theta) p(\mathbf{T} \mid \Theta)\frac{p(\mathbf{T} \mid 
	\mathbf{X}, \Theta_{n})}{p(\mathbf{T} \mid \mathbf{X}, \Theta_{n})}\right) 
	- \log p(\mathbf{X} \mid \Theta_{n}) = \\
	&= \log\left(\sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\frac{p(\mathbf{X} \mid \mathbf{T}, \Theta) p(\mathbf{T} \mid 
	\Theta)}{p(\mathbf{T} \mid \mathbf{X}, \Theta_{n})}\right) - \log 
	p(\mathbf{X} \mid \Theta_{n}) \geq \\
	&\geq \sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\log\left(\frac{p(\mathbf{X} \mid \mathbf{T}, \Theta) 
	p(\mathbf{T} \mid \Theta)}{p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})}\right)  - \log p(\mathbf{X} \mid \Theta_{n}) = \\
	&= \sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\left(\log\left(\frac{p(\mathbf{X} \mid \mathbf{T}, \Theta) 
	p(\mathbf{T} \mid \Theta)}{p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})}\right)  - \log p(\mathbf{X} \mid \Theta_{n})\right) = \\
	&= \sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\log\left(\frac{p(\mathbf{X} \mid \mathbf{T}, \Theta) 
	p(\mathbf{T} \mid \Theta)}{p(\mathbf{X} \mid \Theta_{n})p(\mathbf{T} \mid 
	\mathbf{X}, \Theta_{n})}\right) \equiv \Delta(\Theta \mid \Theta_{n}).
\end{align*}

В результате получаем, что \(L(\Theta) \geq L(\Theta_{n}) + \Delta(\Theta \mid 
\Theta_{n})\). Для удобства введём функцию \(l(\Theta \mid \Theta_{n}) \equiv 
L(\Theta_{n}) + \Delta(\Theta \mid \Theta_{n})\). Тогда наше неравенство имеет 
очень простой вид: \(L(\Theta) \geq l(\Theta \mid \Theta_{n})\). 

Теперь у нас есть функция \(l(\Theta \mid \Theta_{n})\), ограниченная сверху 
лог-функцией правдоподобия \(L(\Theta)\). Заметим, что \(l(\Theta_{n} \mid 
\Theta_{n}) = L(\Theta_{n})\):
\begin{align*}
	l(\Theta_{n}) &= L(\Theta_{n}) + \sum_{\mathbf{T}} p(\mathbf{T} \mid 
	\mathbf{X}, \Theta_{n})\log\left(\frac{p(\mathbf{X} \mid \mathbf{T}, 
	\Theta_{n}) p(\mathbf{T} \mid \Theta_{n})}{p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})p(\mathbf{X} \mid \Theta_{n})}\right) = \\
	&= L(\Theta_{n}) + \sum_{\mathbf{T}} p(\mathbf{T} \mid 
	\mathbf{X}, \Theta_{n})\log\left(\frac{p(\mathbf{X}, \mathbf{T} \mid 
	\Theta_{n})}{p(\mathbf{X}, \mathbf{T} \mid \Theta_{n})}\right) = 
	L(\Theta_{n}).
\end{align*}

Наша цель состоит в выборе значения \(\Theta\) такого, что \(L(\Theta)\) 
максимально. Мы показали, что функция \(l(\Theta \mid \Theta_{n})\) ограничена 
сверху \(L(\Theta)\) и равенство достигается при текущей оценке, то есть при 
\(\Theta = \Theta_{n}\). Следовательно, если \(\Theta\) увеличивает \(l(\Theta 
\mid \Theta_{n})\), то она увеличивает и \(L(\Theta)\). Для получения 
максимального прироста в значении \(L(\Theta)\), EM-алгоритм ищет \(\Theta\) 
такое, что \(l(\Theta \mid \Theta_{n})\) максимально. Это значение обозначают 
через \(\Theta_{n + 1}\). Теперь посчитаем значение \(\Theta_{n + 1}\):
\begin{align*}
	\Theta_{n + 1} &\equiv \arg\max_{\Theta} l(\Theta \mid \Theta_{n}) = \\
	&= \arg\max_{\Theta}\left[L(\Theta_{n}) + \sum_{\mathbf{T}} p(\mathbf{T} 
	\mid \mathbf{X}, \Theta_{n})\log\left(\frac{p(\mathbf{X} \mid \mathbf{T}, 
	\Theta) p(\mathbf{T} \mid \Theta)}{p(\mathbf{X} \mid 
	\Theta_{n})p(\mathbf{T} \mid \mathbf{X}, \Theta_{n})}\right)\right]
\end{align*}

Выбросим все члены, не зависящие от \(\Theta\)~--- они не повлияют на значение 
\(\Theta_{n + 1}\):
\begin{align*}
	\Theta_{n} &= \arg\max_{\Theta}\left[ \sum_{\mathbf{T}} p(\mathbf{T} 
	\mid \mathbf{X}, \Theta_{n})\log\left(p(\mathbf{X} \mid \mathbf{T}, \Theta) 
	p(\mathbf{T} \mid \Theta)\right)\right] = \\
	&= \arg\max_{\Theta}\left[\sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\log p(\mathbf{X}, \mathbf{T} \mid \Theta)\right] = \\
	&= \arg\max_{\Theta} \left[\E_{\mathbf{T} \mid \mathbf{X}, \Theta_{n}}[\log 
	p(\mathbf{X}, \mathbf{T} \mid \Theta)]\right].
\end{align*}

В формуле появляется \(p(\mathbf{T} \mid \mathbf{X}, \Theta_{n})\). Возникает 
вопрос: а как это посчитать? Для этого воспользуемся формулой Байеса:
\[
	p(\mathbf{T} \mid \mathbf{X}, \Theta_{n}) = \frac{p(\mathbf{X}, \mathbf{T} 
	\mid \Theta_{n})}{p(\mathbf{X} \mid \Theta_{n})} = \frac{p(\mathbf{X}, 
	\mathbf{T} \mid \Theta_{n})}{\sum_{\mathbf{T}} p(\mathbf{X}, \mathbf{T} 
	\mid \Theta_{n})}.
\]

Отсюда и получается название: мы \emph{максимизируем} (M) условное 
математическое \emph{ожидание} (E). Теперь можно записать алгоритм формально:
\begin{algorithm}[H]
	\caption{EM-алгоритм}
	\label{em-algorithm-pseudocode}
	\begin{algorithmic}[1]
		\Require Набор наблюдаемых переменных \(\mathbf{X}\)
		\Ensure Набор параметров \(\Theta_{ML}\).
		
		\State Инициализируем \(\Theta_{1}\) каким-либо образом.
		\State \(n \gets 1\).
		\While{алгоритм не сошёлся}
			\State E-шаг: считаем \(\E_{\mathbf{T} \mid \mathbf{X}, 
			\Theta_{n}}[\log p(\mathbf{X}, \mathbf{T} \mid \Theta)]\)
			\State M-шаг: \(\Theta_{n + 1} \gets \arg\max_{\Theta} 
			\left[\E_{\mathbf{T} \mid \mathbf{X}, \Theta_{n}}[\log 
			p(\mathbf{X}, \mathbf{T} \mid \Theta)]\right]\)
			\State \(n \gets n + 1\)
		\EndWhile
	\end{algorithmic}
\end{algorithm}

По сути, этот алгоритм есть ни что иное, как покоординатный спуск: на каждой 
итерации последовательно уточняются возможные значения \(\mathbf{T}\) (E-шаг), 
после чего пересчитывается значение \(\Theta\) (M-шаг).

После всех логических изысканий можно задать вопрос: а зачем всё это? Почему бы 
не максимизировать \(L(\Theta)\) сразу, а не ворочаться с \(l(\Theta \mid 
\Theta_{n})\)? Ответ достаточно прост: \(l(\Theta \mid \Theta_{n})\) учитывает 
скрытые переменные \(T\). В случае, когда мы хотим их определить, EM-алгоритмы 
предоставляют необходимые для этого инструменты. Более того, как мы говорили 
ранее, введение скрытых переменных может быть весьма удобным в том плане, что 
оптимизация \(l(\Theta \mid \Theta_{n})\) будет гораздо проще прямой 
оптимизации \(L(\Theta)\). Например, во многих случаях на M-шаге можно получить 
явные формулы, так как происходит оптимизация выпуклой комбинации логарифмов 
полных правдоподобий.

% Написать про сходимость EM-алгоритма.

Рассмотрим пример применения EM-алгоритма на задаче \emph{разделения 
гауссовской смеси}. Она появляется при попытке приблизить плохо параметризуемые 
распределения смесью гауссиан. Пусть 
\[
	\mathbf{X}\text{~--- выборка размера \(n\) из смеси } \sum_{k = 1}^{l} 
	w_{k}\mathcal{N}(\bm{\mu}_{k}, \bm{\Sigma}_{k}) \in 
	\R^{d}, \quad \sum_{k = 1}^{l} w_{k} = 1.
\]

Задача следующая: нужно восстановить плотность генеральной совокупности, то 
есть определить \(\bm{\mu}_{k}\), \(\bm{\Sigma}_{k}\) и \(w_{k}\). Попробуем 
применить EM-алгоритм. Для начала каким-либо образом инициализируем эти 
параметры, соблюдая ограничения, наложенные на них.

Е-шаг будет устроен следующим образом: для начала определим значение 
\(p(\mathbf{T} \mid \mathbf{X}, \Theta)\). Для этого введём скрытые переменные 
\(\mathbf{z}_{k} \in \{0, 1\}^{l}\), \(z_{k1} + \ldots + z_{kl} = 1\). Они 
будут определять, к какой компоненте принадлежит \(\mathbf{x}_{k}\). Тогда
\[
	p(\mathbf{T} \mid \mathbf{X}, \Theta) = \gamma(z_{ij}) = 
	\frac{w_{j}\mathcal{N}(\mathbf{x}_{i} \mid \bm{\mu}_{j}, 
	\bm{\Sigma}_{j})}{\sum_{k = 1}^{l} w_{k}\mathcal{N}(\mathbf{x}_{k} \mid 
	\bm{\mu}_{k}, \bm{\Sigma}_{k})}.
\]

Далее, выпишем \(\E_{\mathbf{T} \mid \mathbf{X}, \Theta_{n}}[\log p(\mathbf{X}, 
\mathbf{T} \mid \Theta)]\):
\begin{align*}
	\E_{\mathbf{T} \mid \mathbf{X}, \Theta_{n}}[\log p(\mathbf{X}, 
	\mathbf{T} \mid \Theta)] &= \sum_{\mathbf{T}} p(\mathbf{T} \mid \mathbf{X}, 
	\Theta_{n})\log p(\mathbf{X}, \mathbf{T} \mid \Theta) =  \\
	&= \sum_{i = 1}^{n}\sum_{j = 1}^{l} \gamma(z_{ij}) 
	\log(w_{j}\mathcal{N}(\mathbf{x}_{i} \mid \bm{\mu}_{j}, \bm{\Sigma}_{j})) = 
	\\
	&= \sum_{i = 1}^{n}\sum_{j = 1}^{l} \gamma(z_{ij}) 
	\left(\log w_{j} + \log\mathcal{N}(\mathbf{x}_{i} \mid \bm{\mu}_{j}, 
	\bm{\Sigma}_{j})\right)
\end{align*}

Теперь начинаем оптимизровать. Покажем вывод формулы для \(w_{i}\). 
Воспользуемся методом Лагранжа и выпишем лагранжиан:
\[
	\mathcal{L}(\mathbf{w}) = \sum_{i = 1}^{n}\sum_{j = 1}^{l} \gamma(z_{ij}) 
	\log w_{j} + \lambda\left(\sum_{k = 1}^{l} w_{k} - 1\right).
\]

Далее, дифференцируем его по \(w_{j}\) и получаем оптимальное значение:
\[
	\sum_{i = 1}^{n} \frac{\gamma(z_{ij})}{w_{j}} + \lambda = 0 \implies w_{j} 
	= -\frac{1}{\lambda}\sum_{i = 1}^{n} \gamma(z_{ij})
\]

Теперь воспользуемся свойствами \(w_{j}\) и \(\gamma(z_{ij})\):
\[
	\sum_{j = 1}^{l} w_{j} = -\frac{1}{\lambda} \sum_{i = 1}^{n} \sum_{j = 
	1}^{l} \gamma(z_{ij}) = -\frac{n}{\lambda} = 1 \implies \lambda = -n 
	\implies w_{j} = \frac{1}{n}\sum_{i = 1}^{n} \gamma(z_{ij}).
\]

Без доказательства выпишем формулы для \(\bm{\mu}_{k}\) и \(\bm{\Sigma}_{k}\):
\begin{align*}
	N_{j} &= \sum_{i = 1}^{n} \gamma(z_{ij}), \\
	\bm{\mu}_{j} &= \frac{1}{N_{j}}\sum_{i = 1}^{n}\gamma(z_{ij})\bm{x}_{i}, \\
	\bm{\Sigma}_{j} &= \frac{1}{N_{j}}\sum_{i = 1}^{n}\gamma(z_{ij})(\bm{x}_{i} 
	- \bm{\mu}_{j})(\bm{x}_{i} - \bm{\mu}_{j})^{\intercal}.
\end{align*}

Теперь возвращаемся к E-шагу и повторяем процедуру до тех пор, пока алгоритм не 
сойдётся.

У ЕМ-алгоритма много плюсов, но есть и недостатки. Например, он чувствителен к 
начальным приближениям~--- в зависимости от их значений он может сходиться к 
разным точкам. Далее, он находит локальный экстремум. Другими словами, алгоритм 
может сойтись к точке, крайне далёкой от глобального максимума~--- к седловой 
точке или, более того, к локальному минимуму. Впрочем, такое происходит не 
слишком часто. Стоит заметить, что в задаче разделения смеси EM-алгоритм не 
может определить количество компонентов смеси \(l\)~--- оно является 
\emph{структурным параметром}.

\subsection{Сегментация временных рядов}
Задачи о сегментации временных рядов вполне распространены на практике и c ними 
связаны многие методы решения: например, расчёт агрегированных показателей, 
разбиение на равные сегменты и принцип скользящего окна. Однако они не 
универсальны. 

Иногда на практике попадаются временные ряды, устроенные следующим образом: они 
весьма естественно разбиваются на достаточно однородные сегменты. Внутри них 
происходят колебания вокруг какого-то среднего, а после этого происходит резкий 
скачок и сигнал стабилизируется на другом уровне. Сами же скачки происходят 
неравномерно. Такая структура не позволяет эффективно использовать классические 
методы решения. Но при исследовании таких рядов возникла задача применимого на 
практике алгоритма, обеспечивающего выделение достаточно однородных фрагментов, 
удобных для последующей обработки.

Вообще, алгоритмы сегментации можно разделить на две большие группы: 
последовательные (on-line) и апостериорные (off-line). Но большинство 
апостериорных алгоритмов либо разбивает на два сегмента, либо использует 
итерационные вычислительные схемы, где одна итерация имеет сложность порядка
\(O(N^{2})\), где \(N\)~--- длина известной реализации временного ряда. Было 
необходимо разработать апостериорный алгоритм, который, с одной стороны, мог 
разбивать временной ряд на произвольное число сегментов, а, с другой стороны, 
имел адекватную временную сложность. 

Бурнаев и Меньшиков разработали такой апостериорный алгоритм, основанный на 
скрытых марковских моделях. В нём разбиение получается с помощью метода 
максимального правдоподобия. Такое разбиение является <<оптимальным>> в том 
смысле, что с точки зрения теории вероятностей ему соответствует локальный 
максимум функции правдоподобия, а с чисто вычислительной стороны оно 
минимизирует среднеквадратичное отклонение ряда от его средних значений, 
посчитанным по соответствующим сегментам однородности. 

Ближе к делу. Переформулируем задачу сегментации временного ряда в терминах 
задачи максимизации функции правдоподобия некоторой скрытой марковской модели. 
Пусть \(\mathbf{X}^{N} = (x_{1}, \ldots, x_{N})\)~--- известная реализация 
временного ряда. Будем говорить, что \(\mathbf{X}^{N}\) является реализацией 
наблюдаемой части \(\mathbf{X} = (X_{n})_{n \geq 1}\) скрытой марковской 
модели \((\mathbf{S}, \mathbf{X}) = (S_{n}, X_{n})_{n \geq 1}\), где 
\(\mathbf{S} = (S_{n})_{n \geq 1}\)~--- это марковская цепь с \(M\) 
состояниями, то есть \(S_{i} \in \{1, 2, \ldots, M\}\) для всех \(i\). По 
умолчанию будем считать, что начальное состояние марковской цепи \(S_{0} = 1\) 
почти наверное. Далее, введём переходную матрицу \(\mathbf{P}^{M} = 
(p_{ij}) \in \mathrm{M}_{M}(\R)\), для которой \(p_{ij} = 0\) при \(|i - j| > 
1\) и \(p_{MM} = 1\). Тогда по \hyperref[markov-chain-states-theorem]{теореме 
\ref*{markov-chain-states-theorem}}
\[
	\Pr{S_{1} = s_{1}, \ldots, S_{N} = s_{N}} = \prod_{k = 1}^{N} p_{s_{k - 
	1}s_{k}}, \quad s_{0} = 1.
\]

Параметрами марковской цепи \(\mathbf{S}\) являются количество состояний \(M\) 
и переходная матрица \(\mathbf{P}^{M}\).

Теперь посмотрим на \(\mathbf{X}\). Будем считать, что это последовательность 
условно независимых (при фиксированных значениях процесса \(\mathbf{S}\)) 
случайных величин с распределением \(\mathcal{N}(\mu_{\mathbf{S}}, 
\sigma^{2})\), то есть
\begin{multline*}
	\Pr{X_{1} \leq x_{1}, \ldots, X_{n} \leq x_{n} \given S_{1} = s_{1}, 
	\ldots, S_{n} = s_{n}} = \\ = \frac{1}{(2\pi\sigma^{2})^{n/2}} 
	\int\limits_{-\infty}^{x_{1}}\dots\int\limits_{-\infty}^{x_{n}}  
	\exp\left\{-\sum_{k = 1}^{n}\frac{(y_{k} - \mu_{s_{k}})^{2}}{2\sigma^{2}} 
	\right\}\diff y_{1} \ldots \diff y_{n}.
\end{multline*}

Таким образом, параметрами процесса \((\mathbf{S}, \mathbf{X})\) являются 
вектор средних значений \(\bm{\mu} = (\mu_{1}, \ldots, \mu_{M})\), дисперсия 
\(\sigma^{2}\) и матрица переходных вероятностей \(\mathbf{P}^{M}\).

Введём функцию \(J(\mathbf{z})\), равную количеству компонент с разными 
значениями в произвольном векторе \(\mathbf{z} \in \R^{N}\). Далее, пусть 
\(\mathbf{S}_{N} = (s_{1}, \ldots, s_{N})\)~--- наблюдаемая реализация значений 
марковской цепи, соответсвующая реализации наблюдаемой части \(\mathbf{X}^{N} = 
(x_{1}, \ldots, x_{N})\) скрытой марковской модели. Теперь введём обозначение 
\(M_{S} = J(\mathbf{S}^{N})\). Вектором координат сегментов однородности 
временного ряда будем называть вектор \(\mathbf{n}_{S} = (n_{0}, n_{1}, 
\ldots, n_{M_{S}})\), \(n_{0} = 0\), \(n_{M_{s}} = N\), для координат которого 
выполнено неравенство \(s_{n_{i}} \neq s_{n_{i} + 1}\).

Достаточно очевидно, что \(M_{S} \leq M\) и каждому сегменту однородности 
\([n_{i - 1}, n_{i}]\) соответствует состояние \(i\) марковской цепи 
\(\mathbf{S}\) и параметр \(\mu_{i}\) распределений процесса \(\mathbf{X}\). 
Таким образом, оценив по реализации \(\mathbf{X}^{n}\) процесса \(\mathbf{X}\) 
реализацию \(\mathbf{S}_{N}\) процесса \(\mathbf{S}\), можно получить оценку 
вектора \(\mathbf{n}_{S}\) и, тем самым, сегментировать сигнал на участки 
однородности (в смысле постоянства среднего значения).

Будем оценивать \(\mathbf{S}_{N}\) с помощью максимизирования правдоподобия при 
фиксированном \(\mathbf{X}^{N}\). Обозначим условную функцию правдоподобия 
\(\mathbf{S}_{N}\) через \(\mathcal{L}(\mathbf{S}_{N} \mid \mathbf{X}^{N}; M, 
\mathbf{P}^{M}, \bm{\mu}, \sigma)\). Тогда
\[
	\mathbf{S}_{N}^{\mathrm{opt}} = \arg\max\limits_{\mathbf{S}_{N} \in \{1, 
	\ldots, M\}^{N}} \mathcal{L}(\mathbf{S}_{N} \mid \mathbf{X}^{N}; M, 
	\mathbf{P}^{M}, \bm{\mu}, \sigma).
\]

С помощью формулы Байеса можно получить связь между \(\mathcal{L} 
(\mathbf{S}_{N} \mid \mathbf{X}^{N}; M, \mathbf{P}^{M}, \bm{\mu}, \sigma)\) и 
\(\mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, \mathbf{P}^{M}, \bm{\mu}, 
\sigma)\), то есть между условной и совместной функциями правдоподобия:
\[
	\mathcal{L}(\mathbf{S}_{N} \mid \mathbf{X}^{N}; M, \mathbf{P}^{M}, 
	\bm{\mu}, \sigma) = \frac{\mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, 
	\mathbf{P}^{M}, \bm{\mu}, \sigma)}{\mathcal{L}(\mathbf{X}^{N}; M, 
	\mathbf{P}^{M}, \bm{\mu}, \sigma)}.
\]

Как известно, \(\mathcal{L}(\mathbf{X}^{N}; M, \mathbf{P}^{M}, \bm{\mu}, 
\sigma)\) есть ни что иное, как безусловная плотность распределения случайного 
вектора \(\mathbf{X}^{N}\). Следовательно, она не зависит от \(\mathbf{S}^{N}\) 
и задача равносильна максимизации \(\mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; 
M, \mathbf{P}^{M}, \bm{\mu}, \sigma)\) по \(\mathbf{S}^{N}\), где
\[
	\mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, \mathbf{P}^{M}, \bm{\mu}, 
	\sigma) = \frac{1}{(2\pi\sigma^{2})^{n/2}} \prod_{k = 1}^{N} p_{s_{k - 
	1}s_{k}}\exp\left\{-\frac{(x_{k} - \mu_{s_{k}})^{2}}{2\sigma^{2}}\right\}.
\]

Приступим к описанию алгоритма. Но для начала сделаем одно уточнение. Будем 
считать, что на матрицу \(\mathbf{P}^{M}\) наложены следующие условия: \(p_{ii} 
= p\), \(p_{i,i + 1} = 1 - p\) для какого-то \(p \in (0, 1)\) при \(i \in \{1, 
2, \ldots, M - 1\}\) и \(p_{MM} = 1\). В дальнейшем в аргументах функции 
правдоподобия вместо матрицы \(\mathbf{P}^{M}\) будем писать параметр \(p\).

Теперь приступаем к описанию. Начнём с входных и выходных данных.
\begin{itemize}
	\item На вход алгоритму подаются \(\mathbf{X}^{N} = (x_{1}, \ldots, 
	x_{N})\)~--- известная реализация ряда, \(M \leq N/2\)~--- оценка сверху 
	количества сегментов и \(\epsilon\)~--- пороговое значение.
	
	\item Результатом работы алгоритма являются оценки параметров 
	\(p^{\mathrm{opt}}\),\(\bm{\mu}^{\mathrm{opt}}\), 
	\(\sigma^{\mathrm{opt}}\), \(\mathbf{S}_{N}^{\mathrm{opt}}\), 
	\(\mathbf{n}_{S}^{\mathrm{opt}}\) и \(M_{S}^{\mathrm{opt}} = 
	J(\mathbf{S}_{N}^{\mathrm{opt}})\). При этом вполне себе возможна ситуация, 
	когда \(M_{S}^{\mathrm{opt}} < M\).
\end{itemize}

Инициализация алгоритма состоит в следующем:
\begin{itemize}
	\item Начнём с инициализации параметра \(p\): \(p^{(0)} = (N - M)/N\).
	
	\item Далее, \(\mathbf{S}_{N}^{(0)} = (s_{1}^{(0)}, \ldots, s_{N}^{(0)})\) 
	генерируется случайным образом из чисел множества \(\{1, 2, \ldots, M\}\) с 
	соблюдением следующих правил:
	\[
		J(\mathbf{S}_{N}^{(0)}) = M, \quad s_{1}^{(0)} \leq s_{2}^{(0)} \leq 
		\ldots s_{N}^{(0)}.
	\]
	
	\item Сразу же инициализируем оптимальную оценку стандартного отклонения:
	\[
		\sigma^{\mathrm{opt}} = \sqrt{\frac{1}{N - 1}\sum_{k = 1}^{N}(x_{k} - 
		\overline{x})^{2}}, \text{ где } \overline{x} = \frac{1}{N}\sum_{k = 
		1}^{N}x_{k}.
	\]
\end{itemize}

Теперь оговорим условие остановки алгоритма. Пусть \(m\)~--- номер текущей 
итерации. Алгоритм остановит работу в том случае, если изменение функции 
правдоподобия стало достаточно малым:
\[
	|\mathcal{L}(\mathbf{S}_{N}^{(m)}, \mathbf{X}^{N}; M_{S}^{(m)}, p^{(m)}, 
	\bm{\mu}^{(m)}, \sigma^{\mathrm{opt}}) - \mathcal{L}(\mathbf{S}_{N}^{(m - 
	1)}, \mathbf{X}^{N}; M_{S}^{(m - 1)}, p^{(m - 1)}, \bm{\mu}^{(m - 1)}, 
	\sigma^{\mathrm{opt}})| < \epsilon.
\]

Теперь опишем, что происходит на \(m\)-й итерации алгоритма:
\begin{enumerate}
	\item По значению \(\mathbf{S}_{N}^{(m)}\) строится вектор 
	\(\mathbf{n}_{S}^{(m)}\) и определяется \(M_{S}^{(m)} = 
	J(\mathbf{S}_{N}^{(m)})\).
	
	\item По вектору \(\mathbf{n}_{S}^{(m)}\) строится вектор матожиданий 
	\(\bm{\mu}^{(m)} \in \R^{M_{S}^{(m)}}\) по следующему правилу:
	\[
		\mu_{i}^{(m)} = \frac{1}{n_{i} - n_{i - 1}}\sum_{k = n_{i - 1} + 
		1}^{n_{i}} x_{k}, \quad i \in \{1, 2, \ldots, M_{S}^{(m)}\}.
	\]
	
	\item Ищется вероятность \(p^{(m)} = (N - M_{S}^{(m)})/N\).
	
	\item Оценивается значение функции правдоподобия 
	\(\mathcal{L}(\mathbf{S}_{N}^{(m)}, \mathbf{X}^{N}; M^{(m)}, p^{(m)}, 
	\bm{\mu}^{(m)}, \sigma^{\mathrm{opt}})\) и проверяется, выполнено ли 
	условие остановки алгоритма. Если оно подтверждено, то мы получили ответ: 
	\(p^{\mathrm{opt}} = p^{(m)}\),\(\bm{\mu}^{\mathrm{opt}} = 
	\bm{\mu}^{(m)}\), \(\mathbf{S}_{N}^{\mathrm{opt}} = \mathbf{S}_{N}^{(m)}\), 
	\(\mathbf{n}_{S}^{\mathrm{opt}} = \mathbf{n}_{S}^{(m)}\) и 
	\(M_{S}^{\mathrm{opt}} = M_{S}^{(m)} = J(\mathbf{S}_{N}^{(m)})\). Иначе же 
	переходим к следующему шагу.
	
	\item С помощью алгоритма Витерби инициализируем \(\mathbf{S}_{N}^{(m + 
	1)}\):
	\[
		\mathbf{S}_{N}^{(m + 1)} = \arg\max\limits_{\mathbf{S}_{N} \in \{1, 
		\ldots, M_{S}^{(m)}\}^{N}} \mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; 
		M_{S}^{(m)}, p^{(m)}, \bm{\mu}^{(m)}, \sigma^{\mathrm{opt}}).
	\]
	
	 После этого \(m\) увеличивается на единицу и запускается следующая 
	 итерация.
\end{enumerate}

Описанный выше алгоритм, по сути, можно отнести к классу EM-алгоритмов, так как 
сначала алгоритм сводится к подсчёту функции правдоподобия и её максимизации. 
На практике обычно смотрят не на саму функцию правдоподобия, а на её логарифм.

Теперь докажем одно простое утверждение, которое доказывает корректность 
алгоритма.
\begin{theorem}
	Описанный выше алгоритм сходится.
\end{theorem}
\begin{proof}
	Введём следующую функцию:
	\[
		F(\mathbf{S}_{N}, \mathbf{X}^{N}; M, p, \bm{\mu}, \sigma) \equiv -\ln
		\mathcal{L}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, p, \bm{\mu}, \sigma).
	\]
	
	Несложно получить, что
	\[
		F(\mathbf{S}_{N}, \mathbf{X}^{N}; M, p, \bm{\mu}, \sigma) = \sum_{k = 
		1}^{N} \frac{(x_{k} - \mu_{s_{k}})^{2}}{2\sigma^{2}} - \sum_{k = 1}^{N} 
		\ln p_{s_{k - 1}s_{k}} + N\ln(\sigma\sqrt{2\pi}).
	\]
	
	Рассмотрим сумму логарифмов отдельно. Мы можем сказать (по построению 
	\(\mathbf{S}_{N}\)), что \(p_{s_{k - 1}s_{k}}\) равно либо \(p\), либо \(1 
	- p\). Если \(p_{s_{k - 1}s_{k}} = 1 - p\), то \(s_{k} = s_{k - 1} + 1\). 
	Если же \(p_{s_{k - 1}s_{k}} = p\), то \(s_{k} = s_{k - 1}\). Следовательно,
	\[
		\sum_{k = 1}^{N} \ln p_{s_{k - 1}s_{k}} = J(\mathbf{S}_{N})\ln(1 - p) + 
		(N - J(\mathbf{S}_{N}))\ln p = J(\mathbf{S}_{N})\ln\frac{1 - p}{p} + 
		N\ln p.
	\]
	
	Отсюда мы получаем, что верно следующее представление:
	\[
		F(\mathbf{S}_{N}, \mathbf{X}^{N}; M, p, \bm{\mu}, \sigma) = 
		\frac{1}{2\sigma^{2}}F_{1}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, \bm{\mu}) 
		+ F_{2}(\mathbf{S}_{N}; M, p) + N\ln(\sigma\sqrt{2\pi}),
	\]
	где функции \(F_{1}\) и \(F_{2}\) опредеяются следующим образом:
	\[
		F_{1}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, \bm{\mu}) = \sum_{k = 1}^{N} 
		(x_{k} - \mu_{s_{k}})^{2}, \quad F_{2}(\mathbf{S}_{N}; M, p) = 
		J(\mathbf{S}_{N})\ln\frac{p}{1 - p} - N\ln p.
	\]
	
	Теперь заметим, что выполнены три неравенства:
	\begin{itemize}
		\item Для всех \(\bm{\mu} \in \R^{M_{S}^{(m)}}\), где \(M_{S}^{(m)} = 
		J(\mathbf{S}_{N}^{(m)})\), выполнено следующее неравенство:
		\[
			F_{1}(\mathbf{S}_{N}^{(m)}, \mathbf{X}^{N}; M_{S}^{(m)}, \bm{\mu}) 
			\geq F_{1}(\mathbf{S}_{N}^{(m)}, \mathbf{X}^{N}; M_{S}^{(m)}, 
			\bm{\mu}^{(m)}).
		\]
		
		\item Для всех \(p \in (0, 1)\) выполнено, что
		\[
			F_{2}(\mathbf{S}_{N}^{(m)}; M_{S}^{(m)}, p) \geq 
			F_{2}(\mathbf{S}_{N}^{(m)}; M_{S}^{(m)}, p^{(m)}).
		\]
		
		Действительно, возьмём производную по \(p\) и приравняем её к нулю:
		\[
			J(\mathbf{S}_{N}^{(m)})\frac{1 - p}{p}\frac{1 - p + p}{(1 - p)^{2}} 
			- \frac{N}{p} = 0.
		\]
		
		Отсюда получаем, что
		\[
			\frac{J(\mathbf{S}_{N}^{(m)})}{1 - p} = N \implies p = 1 - 
			\frac{J(\mathbf{S}_{N}^{(m)})}{N} = \frac{N - 
			J(\mathbf{S}_{N}^{(m)})}{N} \equiv p^{(m)}.
		\]
		
		Так как при увеличении \(p\) знак производной меняется с отрицательного 
		на положительный, то это действительно минимум.
		
		\item Так как алгоритм Витерби позволяет получить глобальный максимум 
		функции правдоподобия, то для любого 
		\(\mathbf{S}_{N} \in \{1, 2, \ldots, M_{S}^{(m)}\}^{N}\)
		\[
			F(\mathbf{S}_{N}, \mathbf{X}^{N}; M_{S}^{(m)}, p, 
			\bm{\mu}^{(m)}, \sigma) \geq F(\mathbf{S}_{N}^{(m)}, 
			\mathbf{X}^{N}; M_{S}^{(m)}, p, \bm{\mu}^{(m)}, \sigma).
		\]
	\end{itemize}

	Отсюда получаем следующую цепочку равенств:
	\begin{multline*}
		F(\mathbf{S}_{N}^{(m - 1)}, \mathbf{X}^{N}; M_{S}^{(m - 1)}, p^{(m - 
		1)}, \bm{\mu}^{(m - 1)}, \sigma) \geq F(\mathbf{S}_{N}^{(m)}, 
		\mathbf{X}^{N}; M_{S}^{(m - 1)}, p^{(m - 1)}, \bm{\mu}^{(m - 1)}, 
		\sigma) \geq \\ \geq F(\mathbf{S}_{N}^{(m)}, \mathbf{X}^{N}; 
		M_{S}^{(m)}, p^{(m)}, \bm{\mu}^{(m)}, \sigma) \geq F(\mathbf{S}_{N}^{(m 
		+ 1)}, \mathbf{X}^{N}; M_{S}^{(m)}, p^{(m)}, \bm{\mu}^{(m)}, \sigma).
	\end{multline*}
	
	Отсюда получаем, что каждая итерация уменьшает \(F(\mathbf{S}_{N}^{(m)}, 
	\mathbf{X}^{N}; M_{S}^{(m)}, p^{(m)}, \bm{\mu}^{(m)}, \sigma)\). Так как 
	это значение ограничено снизу нулём, то существует предел и алгоритм 
	сходится.
\end{proof}

Теперь выпишем несколько свойств этого алгоритма.
\begin{itemize}
	\item Каждая итерация имеет сложность порядка \(O(NM^{2})\) (такая оценка 
	возникает из-за алгоритма Витерби). Эксперименты показывают, что он 
	сходится за 10-15 итераций, что характерно для алгоритмов типа EM.
	\item Как мы показали выше, минимум \(F_{2}(\mathbf{S}_{N}; M, p)\) 
	достигается при \(p^{\mathrm{opt}} = (N - J(\mathbf{S}_{N}))/N\) и равен
	\begin{align*}
		F_{2}(\mathbf{S}_{N}; M, p^{(m)}) &= 
		J(\mathbf{S}_{N})\ln\left(\frac{N - J(\mathbf{S}_{N})} 
		{J(\mathbf{S}_{N})}\right) - N\ln\left(\frac{N - J(\mathbf{S}_{N})} 
		{N}\right) = \\
		&= J(\mathbf{S}_{N})\ln\left(\frac{N} {J(\mathbf{S}_{N})} - 
		1\right) - N\ln\left(1 - \frac{J(\mathbf{S}_{N})}{N}\right).
	\end{align*}
	
	Оказывается, что \(F_{2}(\mathbf{S}_{N}; M, p^{\mathrm{opt}})\) отвечает за 
	регуляризацию, поскольку при увеличении \(J(\mathbf{S}_{N})\) это слагаемое 
	возрастает, в то время как \(F_{1}(\mathbf{S}_{N}, \mathbf{X}^{N}; M, 
	\bm{\mu})\) убывает (и наоборот). Следовательно, при использовании 
	алгоритма Витерби при минимизации \(F(\mathbf{S}_{N}, \mathbf{X}^{N}; M, p, 
	\bm{\mu}, \sigma)\) по \(\mathbf{S}_{N} \in \{1, 2, \ldots, M\}^{N}\) при 
	фиксированных значениях \(M\) и \(\bm{\mu}\) будет так же выбрано 
	оптимальное число сегментов разбиения, равное \(M_{S} = J(\mathbf{S}_{N}) 
	\leq M\). Вообще говоря, \(M \geq M_{S}^{(0)} \geq M_{S}^{(1)} \geq 
	\ldots\), причём процесс понижения значения \(J(\mathbf{S}_{N})\) со 
	временем стабилизируется, так как иначе значение \(F\) начнёт возрастать.
	
	\item Далее, после стабилизации процесса понижения значения 
	\(J(\mathbf{S}_{N})\), значение \(F\) понижается дальше за счёт 
	<<подстройки>> значений \(\mathbf{n}_{S}\) (и, следовательно, значений, 
	\(\bm{\mu}\)). Описанный нами алгоритм, по сути, ищет такое разбиение, при 
	котором приближение временного ряда его средними значениями по 
	соответствующим сегментам будет оптимальным в смысле среднеквадратичного 
	отклонения.
	
	\item Практика показала следующее: результат работы алгоритма слабо зависит 
	от \(p^{(0)}\) и \(\mathbf{S}_{N}^{(0)}\), но сильно зависит от \(M\). Если 
	взять \(M \ll N\), то с большой вероятностью \(M_{S}^{\mathrm{opt}} = M\). 
	В противном случае \(M_{S}^{\mathrm{opt}} < M\). Более того, если запустить 
	алгоритм с двумя разными параметрами \(M_{1}\) и \(M_{2}\), то полученные 
	значения \(M_{S}^{\mathrm{opt}, 1}\) и \(M_{S}^{\mathrm{opt}, 2}\) не 
	обязательно равны. Это вытекает из того факта, что оптимизируемая функция 
	многоэкстремальна.
\end{itemize}