\begin{center}
	\Huge{У МЕНЯ НЕ БОМБИТ!}
\end{center}
\section{Введение в теорию случайных процессов-1}
Начнём с того, что вспомним такие понятия, как \emph{вероятностное 
пространство} и \emph{случайная величина}.

\begin{definition}
	Вероятностное пространство, или тройка Колмогорова~--- это тройка 
	\((\Omega, \F, \Pr)\), где
	\begin{itemize}
		\item \(\Omega\)~--- простанство элементарных исходов. 
		\item \(\F\)~--- \(\sigma\)-алгебра над \(\Omega\), пространство 
		событий. Неформально говоря, \(\F\) определяет объекты, относительно 
		которых делаются утверждения. 
		\item \(\Pr : \F \mapsto [0, 1]\)~--- вероятностная мера. 
	\end{itemize}
\end{definition}

На всякий случай напомню определения сигма-алгебры и вероятностной меры.
\begin{definition}
	\(\sigma\)-алгебра над множеством \(A\)~--- это множество \(\F \subseteq 
	2^{A}\), обладающее следующими свойствами:
	\begin{enumerate}
		\item \(\emptyset \in \F\).
		\item Если \(X \in \F\), то и дополнение \(A \setminus X \in \F\).
		\item \(\F\) замкнуто относительно счётного объединения, то есть 
		объединение счётного подсемейства из \(F\) лежит в \(F\).\footnote{То 
		есть это алгебра, к которой конечное объединение заменено на счётное.}
	\end{enumerate}
\end{definition}

\begin{definition}
	Пусть \(\Omega\)~--- пространство элементарных исходов, а \(\F\)~--- 
	\(\sigma\)-алгебра его подмножеств (пространство событий). 
	\emph{Вероятностной мерой} или же вероятностью называется функция \(\Pr : 
	\F \mapsto [0, 1]\), удовлетворяющая двум свойствам:
	\begin{enumerate}
		\item (счётная аддитивность) Пусть \(\{A_{n}\}_{n = 1}^{\infty}\)~--- 
		последовательность попарно не пересекающихся событий. Тогда
		\[
			\Pr{\bigsqcup_{n = 1}^{\infty} A_{n}} = \sum_{n = 1}^{\infty} 
			\Pr{A_{n}}
		\]
		
		\item (нормированность) \(\Pr{\Omega} = 1\).
	\end{enumerate}
\end{definition}

Рассмотрим несколько примеров вероятностных пространств:

\begin{example}
	Допустим, что человек бросает монетку. В данном случае элементарными 
	исходами являются ``орёл'' и ``решка''.  Обозначим их за 0 и 1 
	соответственно. Тогда вероятностное пространство будет устроено следующим 
	образом: пространство элементарных исходов \(\Omega = \{0, 1\}\), 
	пространство событий \(\F = \{\emptyset, \{0\}, \{1\}, 
	\Omega\}\), а вероятность \(\Pr\) определяется следующим образом: 
	\[
		\Pr{\emptyset} = 0, \quad \Pr{\{1\}} = p, \quad \quad \Pr{\{0\}} = 1 - 
		p,\quad \quad \Pr{\Omega} = 1, \quad p \in [0, 1].
	\]
\end{example}

\begin{example}
	Теперь подбросим монетку \(n\) раз. В таком случае \(\Omega = \{0, 
	1\}^{n}\), то есть если \(\omega \in \Omega\), то \(\omega = (\omega_{1}, 
	\ldots, \omega_{n})\), где \(\omega_{i} \in \{0, 1\}\). Пространство 
	событий же введём просто как множество всех подмножеств: \(\F = 
	2^{\Omega}\). Введение же вероятностной меры оставим читателю.
\end{example}

\begin{example}
	Теперь перейдём от дискретного случая к более общему. Пусть \(\Omega = 
	\R\). Как тогда ввести множество событий? Ведь, как известно, в \(2^{\R}\) 
	есть неизмеримые по Лебегу множества (то же множество Витали). Для этого 
	вводят \emph{борелевскую \(\sigma\)-алгебру} \(\B(\R)\) и говорят, что \(\F 
	= \B(\R)\). Напомню определение:
\end{example}

\begin{definition}
	Борелевская \(\sigma\)-алгебра над \(\R\) \(\B(\R)\)~--- это минимальная 
	(по включению) сигма-алгебра над \(\R\), содержащая все интервалы.
\end{definition}

\begin{definition}
	Случайная величина \(\xi\)~--- это борелевская функция из \(\Omega\) в 
	\(\R\), то есть для любого \(B \in \B(\R)\) \(\xi^{-1}(B) \in \B(\R)\).
\end{definition}

Теперь введём несколько понятий, напрямую связанных с случайными процессами.
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство, а \(T\)~--- 
	произвольное неслучайное множество (множество индексов). Тогда любое 
	множество случайных величин \(X = \{X_{t} \mid t \in T\}\) называется 
	\emph{случайной функцией}.
\end{definition}

\begin{definition}
	Пусть \(X = (X_{t})_{t \in T}\)~--- случайная функция. Тогда \(X_{t}\) при 
	фиксированном \(t\) называется \emph{сечением} случайного процесса.
\end{definition}

\begin{definition}
	Пусть \(X = (X_{t})_{t \in T}\)~--- случайная функция и \(\omega \in 
	\Omega\)~--- фиксированный исход. \emph{Траекторией} случайного процесса 
	называется функция \(\phi_{\omega} : T \mapsto \R\) такая, что 
	\(\phi_{\omega}(t) = X_{t}(\omega)\). 
\end{definition}

Вообще, случайным функциям обычно дают разные названия в зависимости от вида 
\(T\).
\begin{itemize}
	\item Если \(T = \{1\}\) (или любое другое одноэлементное множество), то 
	\(X = X_{1} : \Omega \mapsto \R\)~--- случайная величина.
	\item Если \(T = \{1, 2, \ldots, N\}\), то \(X = (X_{1}, \ldots, 
	X_{N})\)~--- случайный вектор.
	\item Если \(T\) конечно или же счётно (например, \(\N^{d}\) или \(\Z^{d}\) 
	при \(d > 0\)), то \(X\) называют случайным процессом с дискретным временем.
	\item Если \(T = [a, b]\) для каких-то \(a  < b \in \R\) или же \(T = 
	\R^{d}\), где \(d > 0\), то \(X\) называют случайным процессом с 
	непрерывным временем.
	\item Если \(T = \N^{d}\) или \(\Z^{d}\) или \(\R^{d}\), где \(d > 1\), то 
	\(X\) называют случанйым полем.
\end{itemize}

Рассмотрим некоторые примеры случайных процессов.
\begin{example}
	Пусть \(T = \N\), а \(\Omega = \{0, 1\}\). Тогда случайный процесс \(X = 
	(X_t)_{t \in T}\) соотвествует броскам монетки.
\end{example}
\begin{example}
	Пусть \(T = \R^{3}\). Тогда, например, \(X_{t}(\omega)\) будет 
	соответствовать давлению в точке \(t = (x, y, z)\) в момент времени 
	\(\omega\).
\end{example}
\begin{example}
	Пусть \(T = \N\), а \(\{X_{n}\}_{n = 1}^{\infty}\)~--- последовательность 
	независимых и одинаково распределённых случайных величин.\footnote{Для 
	удобства в дальнейшем будем сокращать ``независимые и одинаково 
	распределённые'' до iid (independent and identically distributed).} Тогда 
	\(X = (X_t)_{t \in T}\)~--- случайный процесс с дискретным временем, 
	называемый \emph{белым шумом}. 
\end{example}
\begin{example}
	Пусть \(Y = (Y_t)_{t \in T}\)~--- белый шум. Тогда построим новую 
	последовательность случайных величин следующим образом: \(X_{t} = Y_{1} + 
	\ldots + Y_{t}\). Тогда \(X = (X_{t})_{t \in T}\)~--- случайный процесс с 
	дискретным временем, называемый \emph{случайным блужданием}. 
\end{example}
\begin{example}
	Пусть \(\xi_{1}, \ldots, \xi_{d}\)~--- случайные величины. Тогда 
	``случайный полином''
	\[
		X = (X_{t})_{t \in \R}, \quad X_t = \sum_{n = 1}^{d} \xi_{n}t^{n}
	\]
	образует случайный процесс.
\end{example}
\begin{example}\label{counting-process}
	Пусть некоторое устройство (например, жёсткий диск) начинает работу в 
	момент времени 0 и ломается в момент времени \(T_{1}\). В этот же момент 
	его меняют на новое (временем замены пренебрегаем). Оно, в свою очередь, 
	ломается спустя время \(T_{2}\), после чего его снова заменяют и этот 
	процесс продолжается. Введём случайные величины \(S_{n} = T_{1} + \dots + 
	T_{n}\). Случайный процесс \(S = (S_{t})_{t \in \N}\) называется процессом 
	моментов восстановления. Сечения будут соответствовать моментам 
	``восстановления''. Далее, введём следующий случайный процесс:
	\[
		N = (N_{t})_{t \in \R}, \quad N_{t} = \sum_{n = 1}^{\infty} 
		\I\{S_{n} \leq t\} = \#\{n \in \N \mid S_{n} \leq t\}.
	\]
	Этот процесс принято называть \emph{процессом восстановления}.
\end{example}

Теперь вопрос: есть случайный процесс. Как описать вероятность того, что 
реализация удовлетворяет какому-то условию? Да и вообще, какие вопросы можно 
задавать относительно реализаций? 

Посмотрим на пару частных случаев случайного процесса \(X = (X_{t})_{t \in T}\)
\begin{enumerate}
	\item Пусть \(T = \{1\}\). Тогда случайный процесс превращается в случайную 
	величину \(\xi\). Но её значения описываются функцией распределения 
	\(F_{\xi}(x) = \Pr{\xi \leq x}\).
	\item Аналогично, пусть \(T = \{1, 2, \dots, n\}\). Тогда \(X = (X_{1}, 
	\dots, X_{n})\)~--- это случайный вектор, а его значения описываются 
	совместной функцией распределения 
	\[
		F_{X}(x_{1}, \dots, x_{n}) = \Pr{X_{1} \leq x_{1}, \dots, X_{n} \leq 
		x_{n}}
	\]
\end{enumerate}

В конечном случае всё хорошо и можно обойтись совместной функцией 
распределения. А как перейти в бесконечный случай? Сделать прямое обобщение 
вряд ли получится: учитывать бесконечное число условий сложно, ибо возникают 
вопросы о той же сходимости. Поэтому будем смотреть на конечные поднаборы. Тем 
самым мы пришли к следующему определению.
\begin{definition}
	Пусть \((\Omega, \F, \Pr)\)~--- вероятностное пространство, \(T\)~--- 
	множество индексов, а \(X = (X_{t})_{t \in T}\)~--- случайный процесс. 
	Тогда \emph{семейством конечномерных распределений} случайного процесса 
	\(X\) называется набор \(F\) его конечномерных функций распределения
	\[
		F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) = \Pr{X_{t_{1}} \leq 
		x_{1}, \ldots, X_{t_{n}} \leq x_{n}},
	\]
	то есть
	\[
		F = \{F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) \mid n \in \N, 
		t_{1}, \dots, t_{n} \in T\}
	\]
\end{definition}

\begin{example}
	Пусть \(X = (X_{t})_{t \in \N}\)~--- случайный процесс, состоящий из iid 
	случайных величин из распределения \(\mathcal{N}(\mu, \sigma^{2})\). Тогда
	\[
		F_{t_{1}, \dots, t_{n}}(x_{1}, \dots, x_{n}) = \prod_{k = 1}^{n} 
		F_{X_{t_{k}}}(x_{k}) = \prod_{k = 1}^{n} \int\limits_{-\infty}^{x_{k}} 
		\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{-\frac{(y - 
		\mu)^{2}}{2\sigma^{2}}\right\}\diff y.
	\]
\end{example}

Вообще говоря, конечномерное распределение \(F_{t_{1}, \dots, t_{n}}(x_{1}, 
\dots, x_{n})\)~--- это распределение случайного вектора \((X_{t_{1}}, \dots, 
X_{t_{n}})\).

Как мы видим, по любому случайному процессу можно построить семейство 
конечномерных функций распределения. Теперь вопрос: а можно ли по семейству 
построить случайный процесс? Оказывается, что можно.
\begin{theorem}[Колмогорова о существовании случайного процесса]
	Пусть \(F\)~--- заданное семейство конечномерных функций распределения над 
	множеством индексов \(T\), которое удовлетворяет свойству согласованности: 
	для \(k < n\)
	\[
		F_{t_{1}, \dots, t_{k}}(x_{1}, \dots, x_{k}) = F_{t_{1}, \dots, 
		t_{n}}(x_{1}, \dots, x_{k}, +\infty, \dots, +\infty)
	\]
	Тогда существует вероятностное пространство \((\Omega, \F, \Pr)\) и 
	случайный процесс \(X = (X_{t})_{t \in T}\) такой, что
	\[
		\Pr{X_{t_{1}} \leq x_{1}, \ldots, X_{t_{n}} \leq x_{n}} = F_{t_{1}, 
		\dots, t_{n}}(x_{1}, \dots, x_{n})
	\]
\end{theorem}
\begin{leftbar}
\begin{small}\noindent
	%TODO: раскурить и написать
	Для доказательства этой теоремы нужно будет понять, что такое \(R^{T}\) и 
	\(\B(\R^{T})\), где \(T \subseteq \R\). Впрочем, первое понятно~--- это 
	множество всех функций из \(T\) в \(\R\). Со вторым интереснее. 
	\begin{proof}
		Положим \(\Omega = R^{T}\), \(\F = \B(\R^{T})\). 
	\end{proof}
\end{small}
\end{leftbar}

Теперь вспомним, что независимость бесконечного набора~--- это независимость в 
совокоуности любого конечного поднабора. Тогда из теоремы Колмогорова сразу же 
получаем следующее
\begin{consequence}
	Пусть для каждого \(t \in T\) определена одномерная функция распределения 
	\(F_{t}(x)\). Тогда существует вероятностное пространство \((\Omega, \F, 
	\Pr)\) и случайный процесс \(X = (X_{t})_{t \in T}\) с независимыми 
	сечениями такой, что
	\[
		\Pr{X_{t} \leq x} = F_{t}(x).
	\]
\end{consequence}

Теперь рассмотрим пример применения этой теоремы. Пусть \(T = [0, 1]\), а 
\[
	F_{t_{1}, \ldots, t_{n}}(x_{1}, \ldots, x_{n}) = \prod_{k = 1}^{n} 
	\int\limits_{-\infty}^{x_{k}} g(y)\diff y,
\]
где \(g\)~--- симметричная относительно нуля плотность. Возьмём случайный 
процесс \(X = (X_{t})_{t \in T}\) из теоремы Колмогорова. Несложно понять, что 
в таком случае
\[
	\Pr{X_{t} > \epsilon, X_{s} < - \epsilon} = 
	\left(\int\limits_{\epsilon}^{\infty}g(y)\diff y\right)^{2}
\]

Теперь возьмём последовательность событий
\[
	A_{n} = \left\{\omega \in \Omega : X_{t}(\omega) > \epsilon, X_{t + 
	\frac{1}{n}}(\omega) < -\epsilon\right\}
\]

Если процесс является непрерывным в самом тупом смысле, то \(A_n \to 
\emptyset\) при \(n \to \infty\). Но тогда нарушается непрерывность в нуле:
\[
	\lim\limits_{n \to \infty} \Pr{A_n} = 
	\left(\int\limits_{\epsilon}^{\infty}g(y)\diff y\right)^{2} \neq 0.
\]

Следовательно, непрерывность почти наверное, независимость и одинаковая 
распределённость не совместимы.

Поехали дальше. Для случайных величин вводились такие вещи, как матожидание и 
дисперсия. Напомню:
\begin{definition}
	\emph{Математическое ожидание} случайной величины \(\xi\) с функцией 
	распределения \(F_{\xi}\)~--- это интеграл Лебега-Стильтьеса
	\[
		\E{\xi} \equiv \int\limits_{-\infty}^{+\infty} x\diff F_{\xi}(x)
	\]
	Если же у случайной величины \(\xi\) есть плотность \(p_{\xi}\), то
	\[
		\E{\xi} = \int\limits_{-\infty}^{+\infty} xp_{\xi}(x)\diff x
	\] 
\end{definition}

Так вот: их можно ввести и для случайных процессов, хотя это уже будут не 
константы, а функции (неслучайные).
\begin{definition}
	Математическое ожидание случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(m : T \mapsto \R\), устроенная следующим образом: \(m(t) = 
	\E{X_{t}}\).
\end{definition}
\begin{definition}
	Дисперсия случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(D : T \mapsto \R\), устроенная следующим образом: \(D(t) = 
	\D{X_{t}} = \E{(X_{t} - \E{X_{t}})^{2}}\).
\end{definition}
\begin{definition}
	Среднеквадратичное отклонение случайного процесса \(X = (X_{t})_{t \in 
	T}\)~--- это функция \(\sigma : T \mapsto \R\), устроенная следующим 
	образом: \(\sigma(t) = \sqrt{\D{X_{t}}}\).
\end{definition}
\begin{definition}
	Ковариационная функция случайного процесса \(X = (X_{t})_{t \in T}\)~--- 
	это функция \(R : T^{2} \mapsto \R\), устроенная следующим образом: 
	\[
		R(t_{1}, t_{2}) = \cov(X_{t_{1}}, X_{t_{2}}) = \E{(X_{t_{1}} - 
		\E{X_{t_{1}}})(X_{t_{2}} - \E{X_{t_{2}}})}
	\]
\end{definition}
Наряду с ковариационной функцией вводят корреляционную функцию
\[
	r(t_{1}, t_{2}) = \frac{R(t_{1}, t_{2})}{\sigma(t_{1})\sigma(t_{2})}
\]

Про неё нужно сказать, что по неравенству Коши-Буняковского-Шварца \(|r(t_{1}, 
t_{2})| \leq 1\).

Осталось ввести ещё одну функцию \(K : T^{2} \mapsto \R\), определяемую 
следующим образом: \(K(t_{1}, t_{2}) = \E{X_{t_{1}}X_{t_{2}}}\).

Теперь выпишем несколько очевидных свойств:
\begin{itemize}
	\item \(D(t) = R(t, t) \geq 0\), так как дисперсия неотрицательна.
	\item \(K(t_{1}, t_{2}) = \E{(X_{t_{1}} - m(t_{1}) + m(t_{1}))(X_{t_{2}} - 
	m(t_{2}) + m(t_{2}))}  = R(t_{1}, t_{2}) + m(t_{1})m(t_{2})\) (проверьте!).
	\item \(R(t_{1}, t_{2}) = R(t_{2}, t_{1})\).
	\item Для любого \(n \in \N\) и наборов \((z_{1}, \ldots, z_{n})\), 
	\((t_{1}, \dots, t_{n})\) матрица \((R(t_{i}, t_{j}))_{n \times n}\) 
	неотрицательно определена:
	\[
		\sum_{i, j = 1}^{n} R(t_{i}, t_{i})z_{i}z_{j} \geq 0
	\]
	
	Это следует из того, что \((X_{t_{1}}, \dots, X_{t_{n}})\)~--- случайный 
	вектор, а \((R(t_{i}, t_{j}))_{n \times n}\) есть его матрица ковариаций.
\end{itemize}

Допустим, что у нас есть какой-то случайный процесс. Что произойдёт с его 
параметрами при линейном преобразовании?

Пусть \(X = (X_{t})_{t \in T}\)~--- случайный процесс, а \(a, b : T \mapsto 
\R\)~--- ограниченные неслучайные функции. Построим новый случайный процесс \(Y 
= (Y_{t})_{t \in T}\) следующим образом: \(Y_t = a(t)X_{t} + b(t)\). Посмотрим 
на матожидание, дисперсию и ковариационную функцию данного процесса. Для того, 
чтобы различать их для разных процессов, будем указывать название процесса в 
качестве индекса: например, \(R_{Y}(t_{1}, t_{2})\).
\begin{gather*}
	m_{Y}(t) = \E{Y_{t}} = \E{a(t)X_{t} + b(t)} = a(t)m_{X}(t) + b(t) \\
	R_{Y}(t_{1}, t_{2}) = \cov(Y_{t_{1}}, Y_{t_{2}}) = \cov(a(t_{1})X_{t_{1}} + 
	b(t_{1}), a(t_{2})X_{t_{2}} + b(t_{2})) = a(t_{1})a(t_{2})R_{X}(t_{1}, 
	t_{2}) \\
	D_{Y}(t) = R_{Y}(t, t) = a^{2}(t)R_{X}(t, t) = a^{2}(t)D_{X}(t)
\end{gather*}

Теперь сделаем небольшое обобщение и возьмём линейную комбинацию \(n\) 
процессов. Пусть \(X_{i} = (X_{t}^{i})_{t \in T}\), \(i = 1, \dots, n\), а 
\(a_{1}, \dots, 
a_{n}\)~--- набор ограниченных функций из \(T\) в \(\R\). Далее, строим новый 
случайный процесс \(Y = (Y_{t})_{t \in T}\) по следующему правилу:
\[
	Y_{t} = \sum_{i = 1}^{n} a_{i}(t)X_{t}^{i}
\]

Для упрощения жизни введём обозначение \(R_{X_{i}, X_{j}}(t_{1}, t_{2}) = 
\cov(X_{t_{1}}^{i}, X_{t_{2}}^{j})\). Тогда несложно показать, что
\begin{gather}
	m_{Y}(t) = \sum_{i = 1}^{n} a_{i}(t)m_{X_{i}}(t) \\
	R_{Y}(t_{1}, t_{2}) = \sum_{i = 1}^{n} 
	a_{i}(t_{1})a_{i}(t_{2})R_{X_{i}}(t_{1}, t_{2}) + \sum_{\substack{i, j = 1 
	\\ i \neq j}}^{n}a_{i}(t_{1})a_{j}(t_{2})R_{X_{i}, X_{j}}(t_{1}, t_{2}) \\
	D_{Y}(t) = \sum_{i = 1}^{n} a^{2}_{i}(t)D_{X_{i}}(t) + \sum_{\substack{i, j 
	= 1 \\ i \neq j}}^{n}a_{i}(t)a_{j}(t)R_{X_{i}, X_{j}}(t, t)
\end{gather}

Дальше по плану сходимости. Как известно, их четыре типа, и они не равноценны. 
Чтобы не повторяться, сразу же введём обозначения. Пусть \((\Omega, \F, 
\Pr)\)~--- вероятностное пространство, а \(\{\xi_{n}\}_{n = 1}^{\infty}\) и 
\(\xi\)~--- случайные величины на нём.
\begin{definition}
	\(\xi_{n}\) сходится к \(\xi\) почти наверное, если 
	\[
		\Pr{\left\{\omega \in \Omega : \lim\limits_{n \to \infty} 
		\xi_{n}(\omega) = \xi(\omega)\right\}} = 1.
	\]
	
	Обозначение: \(\xi_{n} \asto \xi\) или же просто \(\xi_{n} \to \xi\) (если 
	не указан вид сходимости и он не ясен из контекста, то сходимость идёт 
	почти наверное).
\end{definition}
\begin{definition}
	\(\xi_{n}\) сходится к \(\xi\) по вероятности, если для любого \(\epsilon > 
	0\)
	\[
		\lim\limits_{n \to \infty} \Pr{\{\omega \in \Omega : |\xi_{n}(\omega) - 
		\xi(\omega)| > \epsilon\}} = 0.
	\]
	
	Обозначение: \(\xi_{n} \prto \xi\).
\end{definition}
\begin{definition}
	\(\xi_{n}\) сходится к \(\xi\) в среднем порядка \(p\), если
	\[
		\lim\limits_{n \to \infty} \E{|\xi_{n} - \xi|^{p}} = 0.
	\]
	
	Обозначение: \(\xi_{n} \xrightarrow{L_{p}} \xi\).
	
	На практике обычно берётся \(p = 2\). В таком случае говорят, что имеет 
	место сходимость в среднеквадратичном смысле. У такой сходимости есть аж 
	три разных обозначения: \(\xi_{n} \xrightarrow{L_{2}} \xi\), \(\xi_{n} 
	\sqmeanto \xi\) или же вообще \(\xi = \operatorname{l.i.m.} \xi_{n}\).%SWAG
\end{definition}
\begin{definition}
	\(\xi_{n}\) сходятся к \(\xi\) по распределению, если для любой 
	ограниченной непрерывной функции \(f : \R \mapsto \R\)
	\[
		\lim\limits_{n \to \infty} \E{f(\xi_{n})} = \E{f(\xi)}.
	\]
	
	Обозначение: \(\xi_{n} \dto \xi\)
\end{definition}

\begin{definition}
	Случайный процесс \(X = (X_{t})_{t \in T}\) непрерывыен в 
	среднеквадратичном смысле в точке \(t \in T\), если
	\[
		X_{t + \epsilon} \sqmeanto X_{t} \text{ при } \epsilon \to 0.
	\]
	Если это выполнено для любого \(t \in T\), то процесс называют непрерывным 
	в среднеквадратичном смысле.
\end{definition}

Вот есть у нас процесс. Можем ли мы сказать, что он будет непрерывным, не 
вспоминая определение каждый раз? Можем.
% ШТОБЛЯТЬ
\begin{theorem}
	Случайный процесс \(X = (X_{t})_{t \in T}\) непрерывен в среднеквадратичном 
	случае тогда и только тогда, когда непрерывны \(R(t, t)\) и \(m(t)\).
\end{theorem}
\begin{proof}
	Для начала проверим, что этого условия достаточно. Действительно, из 
	непрерывности \(R(t, t)\) и \(m(t)\) следует непрерывность \(K(t, t)\) и
	\[
		\E{(X_{t + \epsilon} - X_{t})^{2}} = \E{X_{t + \epsilon}^{2}} + 
		\E{X_{t}^{2}} - 2\E{X_{t}X_{t + \epsilon}} = K(t + \epsilon, t + 
		\epsilon) + K(t, t) - 2K(t, t + \epsilon).
	\]
	
	Устремляя \(\epsilon\) к нулю, получаем, что \(\E{(X_{t + \epsilon} - 
	X_{t})^{2}} \to 0\), что и даёт непрерывность в среднеквадратичном смысле. 
	Теперь покажем, что это условие необходимо. Для этого воспользуемся 
	следующей леммой:
	\begin{lemma}
		Пусть \(\{X_{n}\}_{n = 1}^{\infty}\), \(\{Y_{n}\}_{n = 1}^{\infty}\), 
		\(X\) и \(Y\)~--- случайные величины такие, что \(X_{n} \sqmeanto X\), 
		\(Y_{n} \sqmeanto Y\), \(\E{X^{2}} < \infty\) и \(\E{Y^{2}} < \infty\). 
		Тогда 
		\[
			\lim\limits_{m, n \to \infty} \E{X_{n}Y_{m}} = \E{XY}.
		\]
	\end{lemma}

	\begin{leftbar}
	\begin{small}\noindent 
	\begin{proof}
		Для начала покажем, что \((\E{XY})^{2} \leq \E{X^{2}}\E{Y^{2}}\). Для 
		этого рассмотрим \(f(t) = \E{(tX + Y)^{2}}\). Понятно, что \(f(t)\) 
		есть квадратный трёхчлен от \(t\) и он неотрицателен. Тогда его 
		дискриминант отрицателен и мы получаем желаемое. По сути, это просто 
		неравенство Коши-Буняковского-Шварца.
		
		Заметим, что по нему
		\[
			\E{(X_{n} - X)(Y_{m} - Y)} \leq \sqrt{\E{(X_{n} - X)^{2}}\E{(Y_{n} 
			- Y)^{2}}} \to 0.
		\]
		
		Теперь раскроем скобки:
		\[
			\E{(X_{n} - X)(Y_{m} - Y)} = \E{X_{n}Y_{m}} - \E{X_{n}Y} - 
			\E{XY_{m}} + \E{XY}
		\]
		Покажем, что \(\E{X_{n}Y} \to \E{XY}\). Действительно,
		\[
			\E{(X_{n} - X)Y} \leq \sqrt{\E{Y^2}\E{(X_{n} - X)^{2}}} \to 0.
		\]
		Аналогично, \(\E{XY_{m}} \to \E{XY}\). Тем самым мы получаем желаемое.
	\end{proof}
	\end{small}
	\end{leftbar}

	Из неё сразу же следует, что при \(\epsilon_{1}, \epsilon_{2} \to 0\)
	\[
		\begin{cases}
			X_{t + \epsilon_{1}} \sqmeanto X_{t} \\
			X_{t + \epsilon_{2}} \sqmeanto X_{t}
		\end{cases}
		\implies
		\E{X_{t + \epsilon_{1}}X_{t + \epsilon_{2}}} \to \E{X_{t}^{2}} \implies 
		K(t + \epsilon_{1}, t + \epsilon_{2}) \to K(t, t)
	\]
	
	Это означает непрерывность \(K(t, t)\). Теперь вспомним, что
	\[
		\D{|X_{t_{1}} - X_{t_{2}}|} = \E{(X_{t_{1}} - X_{t_{2}})^{2}} - 
		\left(\E{|X_{t_{1}} - X_{t_{2}}|}\right)^{2} \geq 0
	\]
	
	Отсюда сразу же следует, что при \(t_{1} \to t_{2}\) \(\E{|X_{t_{1}} - 
	X_{t_{2}}|} \to 0\). Следовательно, \(\E{X_{t_{1}}} \to \E{X_{t_{2}}}\) и 
	\(m(t)\) непрерывна. Отсюда получаем, что и \(R(t, t)\) тоже непрерывна.
\end{proof}
\begin{problem}
	В данном доказательстве есть один очень скользкий момент, связанный с 
	применением леммы. Как его поправить?
\end{problem}

Но не среднеквадратичным случаем единым! У него весьма жёсткие требования, так 
что введём ещё пару видов.
\begin{definition}
	Будем говорить, что \(X = (X_{t})_{t \in T}\)~--- случайный процесс с 
	непрерывными траекториями, если для любого \(\omega \in \Omega\) траектория 
	\(\phi_{\omega}\) непрерывна, как функция от \(t\).
\end{definition}
\begin{definition}
	Будем говорить, что процесс \(X = (X_{t})_{t \in T}\) стохастически 
	непрерывен, если выполняется сходимость по вероятности: для любого 
	\(t \in X_{s} \prto X_{t}\) при \(s \to t\).
\end{definition}

Вообще говоря, между непрерывностями случайных процессов и видами сходимостей 
есть прямая связь. Например, если процесс непрерывен в среднеквадратичном 
смысле будет стохастически непрерывен. Докажем это.
\begin{problem}
	Докажите, что если \(\xi_{n} \sqmeanto \xi\), то \(\xi_{n} \prto \xi\).
\end{problem}
\begin{proof}
	По неравенству Маркова:
	\[
		\Pr{|\xi_{n} - \xi| > \epsilon} = \Pr{(\xi_{n} - \xi)^{2} > 
		\epsilon^{2}} \leq \frac{\E{(\xi_{n} - \xi)^{2}}}{\epsilon^{2}} 
		\xrightarrow[n \to \infty]{} 0. \qedhere
	\]
\end{proof}

Поехали дальше. Вспомним процесс восстановления. Пусть для любого натурального 
\(n\) \(T_{n}\)~--- это iid случайные величины с распределением 
\(\mathrm{Exp}(\lambda)\), то есть их плотность равна \(p(z) = \lambda 
e^{-\lambda z}\I\{z \geq 0\}\). Дальше, \(S_{n} = T_{1} + \ldots + T_{n}\), а 
для любого \(t 
\geq 0\)
\[
	N_{t} = \sum_{n = 1}^{\infty} \I\{S_{n} \leq t\} = \#\{n \in \N : S_{n} 
	< t\}.
\]

Теперь введём понятие \emph{пуассоновского потока}.
\begin{definition}
	Случайный процесс \(X = (X_{t})_{t \geq 0}\) называется пуассоновским 
	потоком с интенсивностью \(\lambda\), если он удовлетворяет трём условиям:
	\begin{enumerate}
		\item \(X_{0} = 0\) почти наверное.
		\item \(X\)~--- процесс с независимыми приращениями, то есть для любых 
		\(t_{0} < t_{1} < \ldots < t_{n} \in T\) случайные величины 
		\(X_{t_{0}}, X_{t_{1}} - X_{t_{0}}, \ldots, X_{t_{n}} - X_{t_{n - 1}}\) 
		независимы в совокупности.
		\item Для всех \(0 \leq s < t < +\infty\) \(X_{t} - X_{s} \sim 
		\mathrm{Pois}(\lambda(t - s))\).
	\end{enumerate}
\end{definition}

Оказывается, что \((N_{t})_{t \geq 0}\) является пуассоновскиим потоком с 
интенсивностью \(\lambda\).
\begin{leftbar}
\begin{small}\noindent
	Докажем это. Для начала покажем, что \(N_{0} = 0\) почти наверное. 
	Действительно, если \(N_{0} = 0\), то все \(T_{n}\) тоже равны нулю, что 
	происходит с нулевой вероятностью. Тем самым \(N_{0} = 0\) почти 
	наверное.
	
	Теперь докажем, что \((N_{t})_{t \geq 0}\) удовлетворяет двум последним 
	свойствам. Для этого заметим, что
	\[
		\begin{pmatrix}
		S_{1} \\ S_{2} \\ S_{3} \\ \vdots \\ S_{n} 
		\end{pmatrix}
		=
		\begin{pmatrix}
		1 & 0 & 0 & \ldots & 0 \\
		1 & 1 & 0 & \ldots & 0 \\
		1 & 1 & 1 & \ldots & 0 \\
		\vdots & \vdots & \vdots & \ddots & \vdots \\
		1 & 1 & 1 & \ldots & 1 \\
		\end{pmatrix}
		\begin{pmatrix}
		T_{1} \\ T_{2} \\ T_{3} \\ \vdots \\ T_{n} 
		\end{pmatrix}
	\]
	
	Так как у матрицы единичный определитель и замена линейна, то
	\[
		p_{S_{1}, \dots, S_{n}}(x_{1}, x_{2}, \dots, x_{n}) = p_{T_{1}, \dots, 
		T_{n}}(x_{1}, x_{2} - x_{1}, \dots, x_{n} - x_{n - 1})
	\]
	
	Пользуясь независимостью \(T_{n}\), получаем, что
	\[
		p_{S_{1}, \dots, S_{n}}(x_{1}, x_{2}, \dots, x_{n}) = \lambda 
		e^{-\lambda x_{1}}\prod_{k = 2}^{n}\lambda e^{-\lambda(x_{k} - x_{k - 
		1})}\I\{x_{k} - x_{k - 1} \geq 0\}
	\]
	
	После преобразования получаем, что
	\[
		p_{S_{1}, \dots, S_{n}}(x_{1}, x_{2}, \dots, x_{n}) = 
		\lambda^{n}e^{-\lambda x_{n}}\I\{x_{n} \geq x_{n - 1} \geq \ldots \geq 
		x_{1} \geq 0\}
	\]
	
	Дальше, зафиксируем какие-либо числа \(0 \leq t_{1} < t_{2} < \dots < 
	t_{n}\), \(k_{1} \leq k_{2} \leq \dots \leq k_{n}\) и посмотрим на 
	следующую вероятность:
	\[
		\Pr{N_{t_{1}} = k_{1}, N_{t_{2}} - N_{t_{1}} = k_{2} - k_{1}, \dots, 
		N_{t_{n}} - N_{t_{n - 1}} = k_{n} -  k_{n - 1}}
	\]
	
	Поймём, как связать это с \(S_{n}\). Для этого поймём, как устроено первое 
	условие. Оно означает, что \(S_{1}, \dots, S_{k_{1}} \leq t_{1}\), а 
	\(S_{k_{1} + 1} > t_{1}\). Аналогично, получаем, что эта вероятность равна
	\[
		\Pr{S_{1}, \dots, S_{k_{1}} \in (0, t_{1}], S_{k_{1} + 1}, \dots, 
		S_{k_{2}} \in (t_{1}, t_{2}], \ldots, S_{k_{n - 1} + 1}, \dots, 
		S_{k_{n}} \in (t_{n - 1}, t_{n}], S_{k_{n} + 1} > t_{n}}
	\]
	
	Пользуясь плотностью случайного вектора из \(S_{k}\), запишем это в виде 
	интеграла:
	\[
		\idotsint\limits_{\mathclap{\substack{0 < x_{1}, \ldots, x_{k_{1}} \leq 
		t_{1} \\ t_{1} < x_{k_{1} + 1}, \ldots, x_{k_{2}} \leq t_{2} \\ \dots 
		\\ t_{n - 1} < x_{k_{n - 1} + 1}, \ldots, x_{k_{n}} \leq t_{n} \\ 
		x_{k_{n} + 1} > t_{n}}}} \lambda^{k_{n} + 1}e^{-\lambda x_{k_{n} + 
		1}}\I\{x_{k_{n} + 1} \geq x_{k_{n}} \geq \ldots \geq x_{1} \geq 
		0\}\diff x_{1} \ldots \diff x_{k_{n}} \diff x_{k_{n} + 1}
	\]
	
	Разобъём его в произведение интегралов, положив \(k_{0} = t_{0} = 0\):
	\[
		\lambda^{k_{n}}\int\limits_{t_{n}}^{\infty} \lambda e^{-\lambda 
		x_{k_{n} + 1}}\diff x_{k_{n} + 1}\prod_{i = 1}^{n} 
		\int\limits_{\substack{t_{j - 1} < x_{k_{j - 1} + 
		1} \leq \ldots \leq x_{k_{j}} \leq t_{j}}} \diff x_{k_{j - 1} + 1} 
		\ldots \diff x_{k_{j}}
	\]
	
	Интегралы в произведении берутся достаточно просто: это объём симплекса. 
	Рассуждая по аналогии с трёхмерным случаем, получаем, что интеграл равен
	\[
		\lambda^{k_{n}}e^{-\lambda t_{n}}\prod_{i = 1}^{n} \frac{(t_{j} - t_{j 
		- 1})^{k_{j} - k_{j - 1}}}{(k_{j} - k_{j - 1})!}
	\]
	
	Теперь сделаем подгон: заметим, что
	\[
		k_{n} = k_{n} - k_{0} = \sum_{j = 1}^{n} (k_{j} - k_{j - 1}), \quad 
		t_{n} = t_{n} - t_{0} = \sum_{j = 1}^{n} (t_{j} - t_{j - 1})
	\]
	
	Тогда интеграл равен
	\[
		\prod_{i = 1}^{n} \frac{(\lambda(t_{j} - t_{j - 1}))^{k_{j} - 
		k_{j - 1}}}{(k_{j} - k_{j - 1})!}e^{-\lambda(t_{j} - t_{j - 1})}.
	\]
	
	Какая красота. Отсюда мы сразу получаем оба свойства. Тем самым процесс 
	восстановления для экспоненциального распределения является пуассоновским 
	потоком с интенсивностью \(\lambda\).
\end{small}
\end{leftbar}

Теперь покажем, что он стохастически непрерывен (справа). Для этого возьмём \(t 
> s\) и посмотрим на вероятность:
\[
	\Pr{|N_{t} - N_{s}| > \epsilon} \leq \Pr{|N_{t} - N_{s}| > 0} = \sum_{k = 
	1}^{\infty} \frac{(\lambda(t - s))^{k}}{k!}e^{-\lambda(t - s)} = 1 - 
	e^{-\lambda(t - s)}.
\]

Но это стремится к нулю при \(t \to s\). Тем самым, \(X_{t} \prto X_{s}\) при 
\(t \to s\) справа. Однако стоит заметить, что \((N_{t})_{t \geq 0}\) имеет 
разрывные траектории, так как \(N_{t}\) принимает только целые значения.

Теперь покажем, что стохастическая непрерывность исключает независимость 
сечений. Пусть \(X = (X_{t})_{t \in T}\)~--- случайный процесс такой, что для 
какой-то окрестности \(t_{0}\) \(X_{t}\) независимо с \(X_{t_{0}}\) и \(X_{t}\) 
имеет плотность \(g(x)\). Посмотрим на вероятность отклониться на \(\epsilon\):
\[
	\Pr{|X_{t} - X_{t_{0}}| > \epsilon} = \iint\limits_{|x - y| > \epsilon} 
	g(x)g(y)\diff x \diff y \xrightarrow[\epsilon \to 0]{} 1 \neq 0.
\]